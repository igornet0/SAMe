#!/usr/bin/env python3
"""
–¢–µ—Å—Ç–æ–≤—ã–π —Å–∫—Ä–∏–ø—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –º–æ–¥—É–ª–µ–π SAMe –∏–∑ notebook
"""

import sys
import os
from pathlib import Path

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –º–æ–¥—É–ª—è–º
sys.path.append(os.path.abspath('.'))

def test_imports():
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –∏–º–ø–æ—Ä—Ç—ã –≤—Å–µ—Ö –º–æ–¥—É–ª–µ–π"""
    print("üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–º–ø–æ—Ä—Ç–æ–≤ –º–æ–¥—É–ª–µ–π SAMe")
    print("=" * 50)
    
    # –¢–µ—Å—Ç 1: –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞
    print("\n1Ô∏è‚É£ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥—É–ª–µ–π –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞...")
    try:
        from same.text_processing.text_cleaner import TextCleaner, CleaningConfig
        print("   ‚úÖ TextCleaner –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω")
    except ImportError as e:
        print(f"   ‚ùå TextCleaner: {e}")

    try:
        from same.text_processing.lemmatizer import Lemmatizer, LemmatizerConfig
        print("   ‚úÖ Lemmatizer –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω")
    except ImportError as e:
        print(f"   ‚ùå Lemmatizer: {e}")

    try:
        from same.text_processing.normalizer import TextNormalizer, NormalizerConfig
        print("   ‚úÖ TextNormalizer –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω")
    except ImportError as e:
        print(f"   ‚ùå TextNormalizer: {e}")
    
    try:
        from same.text_processing.preprocessor import TextPreprocessor, PreprocessorConfig
        print("   ‚úÖ TextPreprocessor –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω")
    except ImportError as e:
        print(f"   ‚ùå TextPreprocessor: {e}")
    
    # –¢–µ—Å—Ç 2: –ü–æ–∏—Å–∫–æ–≤—ã–µ –∞–ª–≥–æ—Ä–∏—Ç–º—ã
    print("\n2Ô∏è‚É£ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ–∏—Å–∫–æ–≤—ã—Ö –º–æ–¥—É–ª–µ–π...")
    try:
        from same.search_engine.fuzzy_search import FuzzySearchEngine, FuzzySearchConfig
        print("   ‚úÖ FuzzySearchEngine –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω")
    except ImportError as e:
        print(f"   ‚ùå FuzzySearchEngine: {e}")
    
    try:
        from same.search_engine.semantic_search import SemanticSearchEngine, SemanticSearchConfig
        print("   ‚úÖ SemanticSearchEngine –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω")
    except ImportError as e:
        print(f"   ‚ùå SemanticSearchEngine: {e}")
    
    try:
        from same.search_engine.hybrid_search import HybridSearchEngine, HybridSearchConfig
        print("   ‚úÖ HybridSearchEngine –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω")
    except ImportError as e:
        print(f"   ‚ùå HybridSearchEngine: {e}")

    try:
        from same.search_engine.indexer import SearchIndexer, IndexConfig
        print("   ‚úÖ SearchIndexer –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω")
    except ImportError as e:
        print(f"   ‚ùå SearchIndexer: {e}")

    # –¢–µ—Å—Ç 3: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
    print("\n3Ô∏è‚É£ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥—É–ª–µ–π –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤...")
    try:
        from same.parameter_extraction.regex_extractor import (
            RegexParameterExtractor, ParameterPattern, ParameterType, ExtractedParameter
        )
        print("   ‚úÖ RegexParameterExtractor –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω")
    except ImportError as e:
        print(f"   ‚ùå RegexParameterExtractor: {e}")

    try:
        from same.parameter_extraction.ml_extractor import MLParameterExtractor, MLExtractorConfig
        print("   ‚úÖ MLParameterExtractor –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω")
    except ImportError as e:
        print(f"   ‚ùå MLParameterExtractor: {e}")

    try:
        from same.parameter_extraction.parameter_parser import ParameterParser, ParameterParserConfig
        print("   ‚úÖ ParameterParser –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω")
    except ImportError as e:
        print(f"   ‚ùå ParameterParser: {e}")

    # –¢–µ—Å—Ç 4: –≠–∫—Å–ø–æ—Ä—Ç
    print("\n4Ô∏è‚É£ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥—É–ª–µ–π —ç–∫—Å–ø–æ—Ä—Ç–∞...")
    try:
        from same.export.excel_exporter import ExcelExporter, ExcelExportConfig
        print("   ‚úÖ ExcelExporter –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω")
    except ImportError as e:
        print(f"   ‚ùå ExcelExporter: {e}")
    
    try:
        from same.export.report_generator import ReportGenerator, ReportConfig
        print("   ‚úÖ ReportGenerator –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω")
    except ImportError as e:
        print(f"   ‚ùå ReportGenerator: {e}")


def test_basic_functionality():
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –±–∞–∑–æ–≤—É—é —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å –º–æ–¥—É–ª–µ–π"""
    print("\nüîß –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –±–∞–∑–æ–≤–æ–π —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏")
    print("=" * 50)
    
    # –¢–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
    sample_data = [
        "–ë–æ–ª—Ç –ú10√ó50 –ì–û–°–¢ 7798-70 –æ—Ü–∏–Ω–∫–æ–≤–∞–Ω–Ω—ã–π",
        "–î–≤–∏–≥–∞—Ç–µ–ª—å –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –ê–ò–†80–í2 1.5–∫–í—Ç 3000–æ–±/–º–∏–Ω",
        "–¢—Ä—É–±–∞ —Å—Ç–∞–ª—å–Ω–∞—è 57√ó3.5 –ì–û–°–¢ 8732-78 –±–µ—Å—à–æ–≤–Ω–∞—è"
    ]
    
    # –¢–µ—Å—Ç TextCleaner
    print("\nüßπ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ TextCleaner...")
    try:
        from same.text_processing.text_cleaner import TextCleaner, CleaningConfig
        
        config = CleaningConfig(
            remove_html=True,
            remove_special_chars=True,
            remove_extra_spaces=True,
            remove_numbers=False
        )
        
        cleaner = TextCleaner(config)
        
        test_text = "<p>–ë–æ–ª—Ç –ú10√ó50 @#$% –ì–û–°–¢ 7798-70</p>"
        result = cleaner.clean_text(test_text)
        
        print(f"   –ò—Å—Ö–æ–¥–Ω—ã–π: '{test_text}'")
        print(f"   –û—á–∏—â–µ–Ω–Ω—ã–π: '{result['normalized']}'")
        print("   ‚úÖ TextCleaner —Ä–∞–±–æ—Ç–∞–µ—Ç")
        
    except Exception as e:
        print(f"   ‚ùå –û—à–∏–±–∫–∞ TextCleaner: {e}")
    
    # –¢–µ—Å—Ç RegexParameterExtractor
    print("\nüîß –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ RegexParameterExtractor...")
    try:
        from same.parameter_extraction.regex_extractor import RegexParameterExtractor
        
        extractor = RegexParameterExtractor()
        
        test_text = "–ë–æ–ª—Ç –ú10√ó50 –¥–∏–∞–º–µ—Ç—Ä 10–º–º –¥–ª–∏–Ω–∞ 50–º–º"
        parameters = extractor.extract_parameters(test_text)
        
        print(f"   –¢–µ–∫—Å—Ç: '{test_text}'")
        print(f"   –ù–∞–π–¥–µ–Ω–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: {len(parameters)}")
        
        for param in parameters[:3]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 3
            print(f"   - {param.name}: {param.value} {param.unit or ''}")
        
        print("   ‚úÖ RegexParameterExtractor —Ä–∞–±–æ—Ç–∞–µ—Ç")
        
    except Exception as e:
        print(f"   ‚ùå –û—à–∏–±–∫–∞ RegexParameterExtractor: {e}")
    
    # –¢–µ—Å—Ç FuzzySearchEngine
    print("\nüîç –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ FuzzySearchEngine...")
    try:
        from same.search_engine.fuzzy_search import FuzzySearchEngine, FuzzySearchConfig
        
        config = FuzzySearchConfig(
            tfidf_max_features=1000,
            similarity_threshold=0.1,
            max_results=3
        )
        
        engine = FuzzySearchEngine(config)
        
        # –û–±—É—á–∞–µ–º –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        document_ids = list(range(1, len(sample_data) + 1))
        engine.fit(sample_data, document_ids)
        
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–æ–∏—Å–∫
        query = "–±–æ–ª—Ç –º10"
        results = engine.search(query)
        
        print(f"   –ó–∞–ø—Ä–æ—Å: '{query}'")
        print(f"   –ù–∞–π–¥–µ–Ω–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {len(results)}")
        
        for i, result in enumerate(results[:2], 1):
            print(f"   {i}. {result['document'][:40]}... (—Å–∫–æ—Ä: {result.get('combined_score', 0):.3f})")
        
        print("   ‚úÖ FuzzySearchEngine —Ä–∞–±–æ—Ç–∞–µ—Ç")
        
    except Exception as e:
        print(f"   ‚ùå –û—à–∏–±–∫–∞ FuzzySearchEngine: {e}")


def test_data_creation():
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç —Å–æ–∑–¥–∞–Ω–∏–µ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö –∫–∞–∫ –≤ notebook"""
    print("\nüìã –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–æ–∑–¥–∞–Ω–∏—è —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö")
    print("=" * 50)
    
    def create_sample_mtr_data():
        """–°–æ–∑–¥–∞–µ—Ç —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –ú–¢–†"""
        return [
            "–ë–æ–ª—Ç –ú10√ó50 –ì–û–°–¢ 7798-70 –æ—Ü–∏–Ω–∫–æ–≤–∞–Ω–Ω—ã–π",
            "–î–≤–∏–≥–∞—Ç–µ–ª—å –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –ê–ò–†80–í2 1.5–∫–í—Ç 3000–æ–±/–º–∏–Ω",
            "–¢—Ä—É–±–∞ —Å—Ç–∞–ª—å–Ω–∞—è 57√ó3.5 –ì–û–°–¢ 8732-78 –±–µ—Å—à–æ–≤–Ω–∞—è",
            "–ì–∞–π–∫–∞ –ú10 —à–µ—Å—Ç–∏–≥—Ä–∞–Ω–Ω–∞—è –ì–û–°–¢ 5915-70",
            "–ö–∞–±–µ–ª—å –í–í–ì 3√ó2.5 –º–º¬≤ 0.66–∫–í –º–µ–¥–Ω—ã–π"
        ]
    
    sample_data = create_sample_mtr_data()
    
    print(f"‚úÖ –°–æ–∑–¥–∞–Ω–æ {len(sample_data)} –æ–±—Ä–∞–∑—Ü–æ–≤ –ú–¢–†")
    print("\nüìù –ü—Ä–∏–º–µ—Ä—ã –¥–∞–Ω–Ω—ã—Ö:")
    for i, item in enumerate(sample_data, 1):
        print(f"{i}. {item}")
    
    return sample_data


def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""
    print("üöÄ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥—É–ª–µ–π SAMe Notebook")
    print("=" * 60)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–±–æ—á—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é
    print(f"üìÅ –†–∞–±–æ—á–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: {os.getcwd()}")
    print(f"üêç Python –≤–µ—Ä—Å–∏—è: {sys.version}")
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º —Ç–µ—Å—Ç—ã
    test_imports()
    test_data_creation()
    test_basic_functionality()
    
    print("\nüéâ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
    print("\nüí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:")
    print("1. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏: pip install matplotlib seaborn")
    print("2. –î–ª—è —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–∏—Å–∫–∞: pip install sentence-transformers faiss-cpu")
    print("3. –î–ª—è SpaCy: pip install spacy && python -m spacy download ru_core_news_lg")
    print("4. –ó–∞–ø—É—Å—Ç–∏—Ç–µ notebook: jupyter notebook SAMe_Demo.ipynb")


if __name__ == "__main__":
    main()
