{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ‚ö†Ô∏è –£–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ –º–∏–≥—Ä–∞—Ü–∏–∏\n",
    "\n",
    "–≠—Ç–æ—Ç notebook –±—ã–ª –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–±–Ω–æ–≤–ª–µ–Ω –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –Ω–æ–≤–æ–π –º–æ–¥—É–ª—å–Ω–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–æ–π SAMe:\n",
    "\n",
    "- üßπ **same_clear** - –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏ –æ—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞\n",
    "- üîç **same_search** - –ü–æ–∏—Å–∫ –∏ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è\n",
    "- üåê **same_api** - API –∏ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏\n",
    "\n",
    "üìö –°–º. [MIGRATION_GUIDE.md](../../MIGRATION_GUIDE.md) –¥–ª—è –ø–æ–¥—Ä–æ–±–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –°–∏—Å—Ç–µ–º–∞ –ø–æ–∏—Å–∫–∞ –∞–Ω–∞–ª–æ–≥–æ–≤ –ø—Ä–æ–¥—É–∫—Ç–æ–≤ –≤ –Ω–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä–µ\n",
    "\n",
    "**Product Analog Search System for Nomenclature Data**\n",
    "\n",
    "–≠—Ç–æ—Ç notebook —Ä–µ–∞–ª–∏–∑—É–µ—Ç —Å–∏—Å—Ç–µ–º—É –ø–æ–∏—Å–∫–∞ –∞–Ω–∞–ª–æ–≥–æ–≤/–ø–æ—Ö–æ–∂–∏—Ö —Ç–æ–≤–∞—Ä–æ–≤ –≤ –æ—Å–Ω–æ–≤–Ω–æ–º –¥–∞—Ç–∞—Å–µ—Ç–µ –Ω–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä—ã, –∏—Å–ø–æ–ª—å–∑—É—è –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ —Å–∏—Å—Ç–µ–º—ã SAMe (Similar Articles Matching Engine).\n",
    "\n",
    "## –¶–µ–ª–∏:\n",
    "- –ê–Ω–∞–ª–∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∞–Ω–Ω—ã—Ö –Ω–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä—ã\n",
    "- –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –æ–ø–∏—Å–∞–Ω–∏–π —Ç–æ–≤–∞—Ä–æ–≤\n",
    "- –†–µ–∞–ª–∏–∑–∞—Ü–∏—è —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤ –ø–æ–∏—Å–∫–∞ –∞–Ω–∞–ª–æ–≥–æ–≤\n",
    "- –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏—Ö –ø—Ä–∏–º–µ—Ä–æ–≤ –ø–æ–∏—Å–∫–∞\n",
    "- –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∏ –∏–º–ø–æ—Ä—Ç—ã"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ –ë–∞–∑–æ–≤—ã–µ –∏–º–ø–æ—Ä—Ç—ã –∑–∞–≥—Ä—É–∂–µ–Ω—ã\n",
      "üìÅ –†–∞–±–æ—á–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: /Users/igor/Desktop/PythonProjects/SAMe/notebooks/analysis\n",
      "üïê –í—Ä–µ–º—è –∑–∞–ø—É—Å–∫–∞: 2025-07-22 11:48:21\n"
     ]
    }
   ],
   "source": [
    "# –°–∏—Å—Ç–µ–º–Ω—ã–µ –∏–º–ø–æ—Ä—Ç—ã\n",
    "import sys\n",
    "import os\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any, Tuple\n",
    "import time\n",
    "from datetime import datetime\n",
    "import re\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 20)\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –º–æ–¥—É–ª—è–º SAMe\n",
    "sys.path.append(os.path.abspath('../../src'))\n",
    "sys.path.append(os.path.abspath('../..'))\n",
    "\n",
    "print(\"‚úÖ –ë–∞–∑–æ–≤—ã–µ –∏–º–ø–æ—Ä—Ç—ã –∑–∞–≥—Ä—É–∂–µ–Ω—ã\")\n",
    "print(f\"üìÅ –†–∞–±–æ—á–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: {os.getcwd()}\")\n",
    "print(f\"üïê –í—Ä–µ–º—è –∑–∞–ø—É—Å–∫–∞: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥—É–ª–µ–π SAMe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ –ú–æ–¥—É–ª–∏ SAMe —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω—ã\n"
     ]
    }
   ],
   "source": [
    "# –ò–º–ø–æ—Ä—Ç—ã –º–æ–¥—É–ª–µ–π SAMe\n",
    "try:\n",
    "    from same.data_manager import data_helper\n",
    "    from same_clear.text_processing.text_cleaner import TextCleaner, CleaningConfig\n",
    "    from same_clear.text_processing.lemmatizer import Lemmatizer, LemmatizerConfig\n",
    "    from same_clear.text_processing.normalizer import TextNormalizer, NormalizerConfig\n",
    "    from same_clear.text_processing.preprocessor import TextPreprocessor, PreprocessorConfig\n",
    "    from same_search.search_engine.fuzzy_search import FuzzySearchEngine, FuzzySearchConfig\n",
    "    from same_search.search_engine.semantic_search import SemanticSearchEngine, SemanticSearchConfig\n",
    "    from same_search.search_engine.hybrid_search import HybridSearchEngine, HybridSearchConfig\n",
    "    from same_clear.parameter_extraction.regex_extractor import RegexParameterExtractor\n",
    "    print(\"‚úÖ –ú–æ–¥—É–ª–∏ SAMe —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω—ã\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå –û—à–∏–±–∫–∞ –∏–º–ø–æ—Ä—Ç–∞ –º–æ–¥—É–ª–µ–π SAMe: {e}\")\n",
    "    print(\"üí° –£–±–µ–¥–∏—Ç–µ—Å—å —á—Ç–æ –º–æ–¥—É–ª–∏ —Å–æ–∑–¥–∞–Ω—ã –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ src/same/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –∞–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞—Ç–∞—Å–µ—Ç: /Users/igor/Desktop/PythonProjects/SAMe/src/data/datasets/main/main_dataset.xlsx\n",
      "‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞—Ç–∞—Å–µ—Ç–∞: [Errno 2] No such file or directory: '/Users/igor/Desktop/PythonProjects/SAMe/src/data/datasets/main/main_dataset.xlsx'\n",
      "üîß –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏...\n"
     ]
    }
   ],
   "source": [
    "# –ó–∞–≥—Ä—É–∑–∫–∞ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞\n",
    "try:\n",
    "    # –ü–æ–ø—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ —Ñ–∞–π–ª —Å —É–∫–∞–∑–∞–Ω–Ω—ã–º –∏–º–µ–Ω–µ–º\n",
    "    dataset_path = data_helper[\"datasets\"] / \"main/–í—ã–≥—Ä—É–∑–∫–∞_–ù–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä–∞_–±–µ–∑_—É–¥–∞–ª–µ–Ω–Ω—ã—Ö_17_07_25.xlsx\"\n",
    "    if not dataset_path.exists():\n",
    "        # –ï—Å–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π —Ñ–∞–π–ª\n",
    "        dataset_path = data_helper[\"datasets\"] / \"/main_dataset.xlsx\"\n",
    "    \n",
    "    print(f\"üìÇ –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞—Ç–∞—Å–µ—Ç: {dataset_path}\")\n",
    "    data = pd.read_excel(dataset_path)\n",
    "    \n",
    "    print(f\"‚úÖ –î–∞—Ç–∞—Å–µ—Ç –∑–∞–≥—Ä—É–∂–µ–Ω —É—Å–ø–µ—à–Ω–æ\")\n",
    "    print(f\"üìä –†–∞–∑–º–µ—Ä –¥–∞—Ç–∞—Å–µ—Ç–∞: {data.shape[0]} —Å—Ç—Ä–æ–∫, {data.shape[1]} —Å—Ç–æ–ª–±—Ü–æ–≤\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞—Ç–∞—Å–µ—Ç–∞: {e}\")\n",
    "    # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏\n",
    "    print(\"üîß –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏...\")\n",
    "    data = pd.DataFrame({\n",
    "        '–ö–æ–¥': ['–ù–ò-001', '–ù–ò-002', '–ù–ò-003', '–ù–ò-004', '–ù–ò-005'],\n",
    "        '–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ': [\n",
    "            '–ë–æ–ª—Ç –ú10√ó50 –ì–û–°–¢ 7798-70 –æ—Ü–∏–Ω–∫–æ–≤–∞–Ω–Ω—ã–π',\n",
    "            '–ë–æ–ª—Ç —Å —à–µ—Å—Ç–∏–≥—Ä–∞–Ω–Ω–æ–π –≥–æ–ª–æ–≤–∫–æ–π –ú12√ó60 DIN 933',\n",
    "            '–í–∏–Ω—Ç –ú8√ó30 —Å –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–º —à–µ—Å—Ç–∏–≥—Ä–∞–Ω–Ω–∏–∫–æ–º',\n",
    "            '–ì–∞–π–∫–∞ –ú10 —à–µ—Å—Ç–∏–≥—Ä–∞–Ω–Ω–∞—è –ì–û–°–¢ 5915-70',\n",
    "            '–®–∞–π–±–∞ –ø–ª–æ—Å–∫–∞—è 10 –ì–û–°–¢ 11371-78'\n",
    "        ],\n",
    "        '–ì—Ä—É–ø–ø–∞': ['–ö—Ä–µ–ø–µ–∂'] * 5,\n",
    "        '–í–∏–¥–ù–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä—ã': ['–ú–∞—Ç–µ—Ä–∏–∞–ª—ã'] * 5\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞:\n",
      "–°—Ç–æ–ª–±—Ü—ã: ['–ö–æ–¥', '–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ', '–ì—Ä—É–ø–ø–∞', '–í–∏–¥–ù–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä—ã']\n",
      "\n",
      "üìä –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –¥–∞–Ω–Ω—ã—Ö:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5 entries, 0 to 4\n",
      "Data columns (total 4 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   –ö–æ–¥              5 non-null      object\n",
      " 1   –ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ     5 non-null      object\n",
      " 2   –ì—Ä—É–ø–ø–∞           5 non-null      object\n",
      " 3   –í–∏–¥–ù–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä—ã  5 non-null      object\n",
      "dtypes: object(4)\n",
      "memory usage: 292.0+ bytes\n",
      "None\n",
      "\n",
      "üîç –ü–µ—Ä–≤—ã–µ 5 –∑–∞–ø–∏—Å–µ–π:\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "–ö–æ–¥",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "–ì—Ä—É–ø–ø–∞",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "–í–∏–¥–ù–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä—ã",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "94ff18be-2ce9-4ff6-ae90-3714de7ca917",
       "rows": [
        [
         "0",
         "–ù–ò-001",
         "–ë–æ–ª—Ç –ú10√ó50 –ì–û–°–¢ 7798-70 –æ—Ü–∏–Ω–∫–æ–≤–∞–Ω–Ω—ã–π",
         "–ö—Ä–µ–ø–µ–∂",
         "–ú–∞—Ç–µ—Ä–∏–∞–ª—ã"
        ],
        [
         "1",
         "–ù–ò-002",
         "–ë–æ–ª—Ç —Å —à–µ—Å—Ç–∏–≥—Ä–∞–Ω–Ω–æ–π –≥–æ–ª–æ–≤–∫–æ–π –ú12√ó60 DIN 933",
         "–ö—Ä–µ–ø–µ–∂",
         "–ú–∞—Ç–µ—Ä–∏–∞–ª—ã"
        ],
        [
         "2",
         "–ù–ò-003",
         "–í–∏–Ω—Ç –ú8√ó30 —Å –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–º —à–µ—Å—Ç–∏–≥—Ä–∞–Ω–Ω–∏–∫–æ–º",
         "–ö—Ä–µ–ø–µ–∂",
         "–ú–∞—Ç–µ—Ä–∏–∞–ª—ã"
        ],
        [
         "3",
         "–ù–ò-004",
         "–ì–∞–π–∫–∞ –ú10 —à–µ—Å—Ç–∏–≥—Ä–∞–Ω–Ω–∞—è –ì–û–°–¢ 5915-70",
         "–ö—Ä–µ–ø–µ–∂",
         "–ú–∞—Ç–µ—Ä–∏–∞–ª—ã"
        ],
        [
         "4",
         "–ù–ò-005",
         "–®–∞–π–±–∞ –ø–ª–æ—Å–∫–∞—è 10 –ì–û–°–¢ 11371-78",
         "–ö—Ä–µ–ø–µ–∂",
         "–ú–∞—Ç–µ—Ä–∏–∞–ª—ã"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>–ö–æ–¥</th>\n",
       "      <th>–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ</th>\n",
       "      <th>–ì—Ä—É–ø–ø–∞</th>\n",
       "      <th>–í–∏–¥–ù–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä—ã</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>–ù–ò-001</td>\n",
       "      <td>–ë–æ–ª—Ç –ú10√ó50 –ì–û–°–¢ 7798-70 –æ—Ü–∏–Ω–∫–æ–≤–∞–Ω–Ω—ã–π</td>\n",
       "      <td>–ö—Ä–µ–ø–µ–∂</td>\n",
       "      <td>–ú–∞—Ç–µ—Ä–∏–∞–ª—ã</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>–ù–ò-002</td>\n",
       "      <td>–ë–æ–ª—Ç —Å —à–µ—Å—Ç–∏–≥—Ä–∞–Ω–Ω–æ–π –≥–æ–ª–æ–≤–∫–æ–π –ú12√ó60 DIN 933</td>\n",
       "      <td>–ö—Ä–µ–ø–µ–∂</td>\n",
       "      <td>–ú–∞—Ç–µ—Ä–∏–∞–ª—ã</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>–ù–ò-003</td>\n",
       "      <td>–í–∏–Ω—Ç –ú8√ó30 —Å –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–º —à–µ—Å—Ç–∏–≥—Ä–∞–Ω–Ω–∏–∫–æ–º</td>\n",
       "      <td>–ö—Ä–µ–ø–µ–∂</td>\n",
       "      <td>–ú–∞—Ç–µ—Ä–∏–∞–ª—ã</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>–ù–ò-004</td>\n",
       "      <td>–ì–∞–π–∫–∞ –ú10 —à–µ—Å—Ç–∏–≥—Ä–∞–Ω–Ω–∞—è –ì–û–°–¢ 5915-70</td>\n",
       "      <td>–ö—Ä–µ–ø–µ–∂</td>\n",
       "      <td>–ú–∞—Ç–µ—Ä–∏–∞–ª—ã</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>–ù–ò-005</td>\n",
       "      <td>–®–∞–π–±–∞ –ø–ª–æ—Å–∫–∞—è 10 –ì–û–°–¢ 11371-78</td>\n",
       "      <td>–ö—Ä–µ–ø–µ–∂</td>\n",
       "      <td>–ú–∞—Ç–µ—Ä–∏–∞–ª—ã</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      –ö–æ–¥                                 –ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ  –ì—Ä—É–ø–ø–∞ –í–∏–¥–ù–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä—ã\n",
       "0  –ù–ò-001        –ë–æ–ª—Ç –ú10√ó50 –ì–û–°–¢ 7798-70 –æ—Ü–∏–Ω–∫–æ–≤–∞–Ω–Ω—ã–π  –ö—Ä–µ–ø–µ–∂       –ú–∞—Ç–µ—Ä–∏–∞–ª—ã\n",
       "1  –ù–ò-002  –ë–æ–ª—Ç —Å —à–µ—Å—Ç–∏–≥—Ä–∞–Ω–Ω–æ–π –≥–æ–ª–æ–≤–∫–æ–π –ú12√ó60 DIN 933  –ö—Ä–µ–ø–µ–∂       –ú–∞—Ç–µ—Ä–∏–∞–ª—ã\n",
       "2  –ù–ò-003       –í–∏–Ω—Ç –ú8√ó30 —Å –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–º —à–µ—Å—Ç–∏–≥—Ä–∞–Ω–Ω–∏–∫–æ–º  –ö—Ä–µ–ø–µ–∂       –ú–∞—Ç–µ—Ä–∏–∞–ª—ã\n",
       "3  –ù–ò-004          –ì–∞–π–∫–∞ –ú10 —à–µ—Å—Ç–∏–≥—Ä–∞–Ω–Ω–∞—è –ì–û–°–¢ 5915-70  –ö—Ä–µ–ø–µ–∂       –ú–∞—Ç–µ—Ä–∏–∞–ª—ã\n",
       "4  –ù–ò-005               –®–∞–π–±–∞ –ø–ª–æ—Å–∫–∞—è 10 –ì–û–°–¢ 11371-78  –ö—Ä–µ–ø–µ–∂       –ú–∞—Ç–µ—Ä–∏–∞–ª—ã"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìù –û—Å–Ω–æ–≤–Ω–æ–π —Å—Ç–æ–ª–±–µ—Ü —Å –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏—è–º–∏: '–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ'\n"
     ]
    }
   ],
   "source": [
    "# –ê–Ω–∞–ª–∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∞–Ω–Ω—ã—Ö\n",
    "print(\"üìã –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞:\")\n",
    "print(f\"–°—Ç–æ–ª–±—Ü—ã: {list(data.columns)}\")\n",
    "print(f\"\\nüìä –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –¥–∞–Ω–Ω—ã—Ö:\")\n",
    "print(data.info())\n",
    "\n",
    "print(f\"\\nüîç –ü–µ—Ä–≤—ã–µ 5 –∑–∞–ø–∏—Å–µ–π:\")\n",
    "display(data.head())\n",
    "\n",
    "# –û–ø—Ä–µ–¥–µ–ª—è–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π —Å—Ç–æ–ª–±–µ—Ü —Å –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏—è–º–∏\n",
    "name_columns = [col for col in data.columns if '–Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ' in col.lower() or '–Ω–∞–∑–≤–∞–Ω–∏–µ' in col.lower()]\n",
    "if name_columns:\n",
    "    main_name_column = name_columns[0]\n",
    "    print(f\"\\nüìù –û—Å–Ω–æ–≤–Ω–æ–π —Å—Ç–æ–ª–±–µ—Ü —Å –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏—è–º–∏: '{main_name_column}'\")\n",
    "else:\n",
    "    main_name_column = data.columns[1] if len(data.columns) > 1 else data.columns[0]\n",
    "    print(f\"\\nüìù –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–æ–ª–±–µ—Ü: '{main_name_column}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç –ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–∞–Ω–Ω—ã—Ö:\n",
      "–ü—É—Å—Ç—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –≤ –æ—Å–Ω–æ–≤–Ω–æ–º —Å—Ç–æ–ª–±—Ü–µ: 0\n",
      "–î—É–±–ª–∏–∫–∞—Ç—ã: 0\n",
      "–£–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –≤ '–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ': 5\n",
      "\n",
      "üìè –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–ª–∏–Ω—ã –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–π:\n",
      "–°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞: 36.6 —Å–∏–º–≤–æ–ª–æ–≤\n",
      "–ú–µ–¥–∏–∞–Ω–∞: 37.0 —Å–∏–º–≤–æ–ª–æ–≤\n",
      "–ú–∏–Ω/–ú–∞–∫—Å: 30/43 —Å–∏–º–≤–æ–ª–æ–≤\n",
      "\n",
      "üìù –ü—Ä–∏–º–µ—Ä—ã –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–π:\n",
      "1. –ì–∞–π–∫–∞ –ú10 —à–µ—Å—Ç–∏–≥—Ä–∞–Ω–Ω–∞—è –ì–û–°–¢ 5915-70\n",
      "2. –ë–æ–ª—Ç –ú10√ó50 –ì–û–°–¢ 7798-70 –æ—Ü–∏–Ω–∫–æ–≤–∞–Ω–Ω—ã–π\n",
      "3. –®–∞–π–±–∞ –ø–ª–æ—Å–∫–∞—è 10 –ì–û–°–¢ 11371-78\n",
      "4. –í–∏–Ω—Ç –ú8√ó30 —Å –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–º —à–µ—Å—Ç–∏–≥—Ä–∞–Ω–Ω–∏–∫–æ–º\n",
      "5. –ë–æ–ª—Ç —Å —à–µ—Å—Ç–∏–≥—Ä–∞–Ω–Ω–æ–π –≥–æ–ª–æ–≤–∫–æ–π –ú12√ó60 DIN 933\n"
     ]
    }
   ],
   "source": [
    "# –ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–∞–Ω–Ω—ã—Ö\n",
    "print(\"üîç –ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–∞–Ω–Ω—ã—Ö:\")\n",
    "print(f\"–ü—É—Å—Ç—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –≤ –æ—Å–Ω–æ–≤–Ω–æ–º —Å—Ç–æ–ª–±—Ü–µ: {data[main_name_column].isnull().sum()}\")\n",
    "print(f\"–î—É–±–ª–∏–∫–∞—Ç—ã: {data.duplicated(subset=[main_name_column], keep=False).sum()}\")\n",
    "print(f\"–£–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –≤ '{main_name_column}': {data[main_name_column].nunique()}\")\n",
    "\n",
    "# –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –¥–ª–∏–Ω–µ –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–π\n",
    "name_lengths = data[main_name_column].dropna().str.len()\n",
    "print(f\"\\nüìè –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–ª–∏–Ω—ã –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–π:\")\n",
    "print(f\"–°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞: {name_lengths.mean():.1f} —Å–∏–º–≤–æ–ª–æ–≤\")\n",
    "print(f\"–ú–µ–¥–∏–∞–Ω–∞: {name_lengths.median():.1f} —Å–∏–º–≤–æ–ª–æ–≤\")\n",
    "print(f\"–ú–∏–Ω/–ú–∞–∫—Å: {name_lengths.min()}/{name_lengths.max()} —Å–∏–º–≤–æ–ª–æ–≤\")\n",
    "\n",
    "# –ü—Ä–∏–º–µ—Ä—ã –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–π —Ä–∞–∑–Ω–æ–π –¥–ª–∏–Ω—ã\n",
    "print(f\"\\nüìù –ü—Ä–∏–º–µ—Ä—ã –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–π:\")\n",
    "sample_names = data[main_name_column].dropna().sample(min(5, len(data))).tolist()\n",
    "for i, name in enumerate(sample_names, 1):\n",
    "    print(f\"{i}. {name[:80]}{'...' if len(name) > 80 else ''}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å–∏—Å—Ç–µ–º—ã –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–ª—è —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–π –Ω–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä—ã...\n",
      "\n",
      "üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ SpaCy –º–æ–¥–µ–ª–µ–π...\n",
      "‚úÖ –ú–æ–¥–µ–ª—å SpaCy 'ru_core_news_lg' –Ω–∞–π–¥–µ–Ω–∞ –∏ –∑–∞–≥—Ä—É–∂–µ–Ω–∞\n",
      "‚úÖ –£–ª—É—á—à–µ–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø—Ä–æ—Å—Ç–æ–π –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–æ–∑–¥–∞–Ω–∞\n"
     ]
    }
   ],
   "source": [
    "# –£–ª—É—á—à–µ–Ω–Ω–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ —Å–∏—Å—Ç–µ–º—ã –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞ –¥–ª—è —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–π –Ω–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä—ã\n",
    "print(\"üîß –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å–∏—Å—Ç–µ–º—ã –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–ª—è —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–π –Ω–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä—ã...\")\n",
    "\n",
    "def check_spacy_model(model_name: str = \"ru_core_news_lg\") -> bool:\n",
    "    \"\"\"\n",
    "    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–∞–ª–∏—á–∏–µ –º–æ–¥–µ–ª–∏ SpaCy –∏ –ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç —É—Å—Ç–∞–Ω–æ–≤–∫—É –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏\n",
    "    \"\"\"\n",
    "    try:\n",
    "        import spacy\n",
    "        spacy.load(model_name)\n",
    "        print(f\"‚úÖ –ú–æ–¥–µ–ª—å SpaCy '{model_name}' –Ω–∞–π–¥–µ–Ω–∞ –∏ –∑–∞–≥—Ä—É–∂–µ–Ω–∞\")\n",
    "        return True\n",
    "    except OSError:\n",
    "        print(f\"‚ö†Ô∏è –ú–æ–¥–µ–ª—å SpaCy '{model_name}' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞\")\n",
    "        print(f\"üì• –î–ª—è —É—Å—Ç–∞–Ω–æ–≤–∫–∏ –≤—ã–ø–æ–ª–Ω–∏—Ç–µ –∫–æ–º–∞–Ω–¥—É:\")\n",
    "        print(f\"   python -m spacy download {model_name}\")\n",
    "        print(f\"üí° –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–æ –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å 'ru_core_news_lg' –¥–ª—è –ª—É—á—à–µ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞\")\n",
    "        return False\n",
    "    except ImportError:\n",
    "        print(f\"‚ùå SpaCy –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install spacy\")\n",
    "        return False\n",
    "\n",
    "# –°–ª–æ–≤–∞—Ä–∏ –¥–ª—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤ (–≥–ª–æ–±–∞–ª—å–Ω—ã–µ –¥–ª—è —Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏–∏)\n",
    "TECHNICAL_ABBREVIATIONS = {\n",
    "    '—ç–ª': '—ç–ª–µ–∫—Ç—Ä–∏—á–µ—Å–∫–∏–π', '—ç–ª–µ–∫—Ç—Ä': '—ç–ª–µ–∫—Ç—Ä–∏—á–µ—Å–∫–∏–π',\n",
    "    '–º–µ—Ö': '–º–µ—Ö–∞–Ω–∏—á–µ—Å–∫–∏–π', '–≥–∏–¥—Ä': '–≥–∏–¥—Ä–∞–≤–ª–∏—á–µ—Å–∫–∏–π',\n",
    "    '–ø–Ω–µ–≤–º': '–ø–Ω–µ–≤–º–∞—Ç–∏—á–µ—Å–∫–∏–π', '–∞–≤—Ç': '–∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π',\n",
    "    '—Ä—É—á': '—Ä—É—á–Ω–æ–π', '—Å—Ç–∞—Ü': '—Å—Ç–∞—Ü–∏–æ–Ω–∞—Ä–Ω—ã–π',\n",
    "    '–ø–µ—Ä–µ–Ω': '–ø–µ—Ä–µ–Ω–æ—Å–Ω–æ–π', '–º–æ–±–∏–ª': '–º–æ–±–∏–ª—å–Ω—ã–π',\n",
    "    '–Ω–µ—Ä–∂': '–Ω–µ—Ä–∂–∞–≤–µ—é—â–∏–π', '–æ—Ü–∏–Ω–∫': '–æ—Ü–∏–Ω–∫–æ–≤–∞–Ω–Ω—ã–π'\n",
    "}\n",
    "\n",
    "# –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ (–≥–ª–æ–±–∞–ª—å–Ω—ã–µ –¥–ª—è —Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏–∏)\n",
    "TECHNICAL_PATTERNS = [\n",
    "    r'\\b\\d+[.,]?\\d*\\s*[–∞-—è—ë]*[–≤—Ç|–∞|–≤|–æ–º|–º–º|—Å–º|–º|–∫–≥|–≥|–ª|–º–ª]\\b',  # –†–∞–∑–º–µ—Ä—ã –∏ –µ–¥–∏–Ω–∏—Ü—ã\n",
    "    r'\\b[–º–º]\\d+[x√ó]\\d+\\b',  # –†–∞–∑–º–µ—Ä—ã —Ç–∏–ø–∞ –ú10√ó50\n",
    "    r'\\b[–≥–æ—Å—Ç|din|iso]\\s*\\d+[-]?\\d*[-]?\\d*\\b',  # –°—Ç–∞–Ω–¥–∞—Ä—Ç—ã\n",
    "    r'\\b\\d+[.,]\\d*\\s*[–∫–≤—Ç|–∫–≤|–º–≤—Ç|–≤—Ç]\\b',  # –ú–æ—â–Ω–æ—Å—Ç—å\n",
    "    r'\\b\\d+\\s*–æ–±[/.]–º–∏–Ω\\b',  # –û–±–æ—Ä–æ—Ç—ã\n",
    "    r'\\b\\d+[.,]\\d*\\s*[–º–ø–∞|–∫–ø–∞|–ø–∞|–±–∞—Ä]\\b',  # –î–∞–≤–ª–µ–Ω–∏–µ\n",
    "    r'\\b\\d+[.,]\\d*\\s*[–º–º|—Å–º|–º]\\b'  # –†–∞–∑–º–µ—Ä—ã\n",
    "]\n",
    "\n",
    "def enhanced_simple_preprocess(text):\n",
    "    \"\"\"\n",
    "    –£–ª—É—á—à–µ–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø—Ä–æ—Å—Ç–æ–π –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–ª—è —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö —Ç–µ–∫—Å—Ç–æ–≤\n",
    "    –¢–µ–ø–µ—Ä—å —ç—Ç–æ –≥–ª–æ–±–∞–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è, –∫–æ—Ç–æ—Ä—É—é –º–æ–∂–Ω–æ —Å–µ—Ä–∏–∞–ª–∏–∑–æ–≤–∞—Ç—å —Å pickle\n",
    "    \"\"\"\n",
    "    if pd.isna(text) or not text:\n",
    "        return \"\"\n",
    "    \n",
    "    text = str(text).strip()\n",
    "    original_text = text.lower()\n",
    "    \n",
    "    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏\n",
    "    preserved_terms = []\n",
    "    for pattern in TECHNICAL_PATTERNS:\n",
    "        matches = re.findall(pattern, original_text)\n",
    "        preserved_terms.extend(matches)\n",
    "    \n",
    "    # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö —Å–æ–∫—Ä–∞—â–µ–Ω–∏–π\n",
    "    for abbr, full_form in TECHNICAL_ABBREVIATIONS.items():\n",
    "        original_text = re.sub(rf'\\b{abbr}\\b', full_form, original_text)\n",
    "    \n",
    "    # –û—á–∏—Å—Ç–∫–∞ –æ—Ç –ª–∏—à–Ω–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤, –Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö\n",
    "    original_text = re.sub(r'[^–∞-—è—ëa-z\\w\\s\\d.,()√óx/-]', ' ', original_text)\n",
    "    original_text = re.sub(r'\\s+', ' ', original_text)\n",
    "    \n",
    "    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ç–µ—Ä–º–∏–Ω—ã\n",
    "    if preserved_terms:\n",
    "        original_text = original_text + ' ' + ' '.join(preserved_terms)\n",
    "    \n",
    "    return original_text.strip()\n",
    "\n",
    "def create_enhanced_simple_preprocess():\n",
    "    \"\"\"\n",
    "    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —É–ª—É—á—à–µ–Ω–Ω—É—é —Ñ—É–Ω–∫—Ü–∏—é –ø—Ä–æ—Å—Ç–æ–π –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–ª—è —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö —Ç–µ–∫—Å—Ç–æ–≤\n",
    "    –¢–µ–ø–µ—Ä—å –ø—Ä–æ—Å—Ç–æ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≥–ª–æ–±–∞–ª—å–Ω—É—é —Ñ—É–Ω–∫—Ü–∏—é –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏\n",
    "    \"\"\"\n",
    "    return enhanced_simple_preprocess\n",
    "\n",
    "# –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å SpaCy –º–æ–¥–µ–ª–∏\n",
    "print(\"\\nüîç –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ SpaCy –º–æ–¥–µ–ª–µ–π...\")\n",
    "spacy_available = check_spacy_model(\"ru_core_news_lg\")\n",
    "\n",
    "if not spacy_available:\n",
    "    # –ü—Ä–æ–±—É–µ–º –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—É—é –º–æ–¥–µ–ª—å\n",
    "    print(\"\\nüîÑ –ü—Ä–æ–±—É–µ–º –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—É—é –º–æ–¥–µ–ª—å...\")\n",
    "    spacy_available = check_spacy_model(\"ru_core_news_lg\")\n",
    "    if spacy_available:\n",
    "        spacy_model = \"ru_core_news_lg\"\n",
    "    else:\n",
    "        spacy_model = \"ru_core_news_lg\"\n",
    "        print(\"\\n‚ö†Ô∏è SpaCy –º–æ–¥–µ–ª–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã. –ë—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∞ —É–ø—Ä–æ—â–µ–Ω–Ω–∞—è –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞.\")\n",
    "else:\n",
    "    spacy_model = \"ru_core_news_lg\"\n",
    "\n",
    "# –°–æ–∑–¥–∞–µ–º —É–ª—É—á—à–µ–Ω–Ω—É—é —Ñ—É–Ω–∫—Ü–∏—é –ø—Ä–æ—Å—Ç–æ–π –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏\n",
    "enhanced_simple_preprocess = create_enhanced_simple_preprocess()\n",
    "print(\"‚úÖ –£–ª—É—á—à–µ–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø—Ä–æ—Å—Ç–æ–π –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–æ–∑–¥–∞–Ω–∞\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚öôÔ∏è –°–æ–∑–¥–∞–Ω–∏–µ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π...\n",
      "üìã –°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π —Å –ø—Ä–æ–≤–µ—Ä–µ–Ω–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏...\n",
      "‚úÖ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ —Å–æ–∑–¥–∞–Ω—ã —Å —Å–æ–≤–º–µ—Å—Ç–∏–º—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏\n",
      "\n",
      "üí° –ü—Ä–∏–º–µ—á–∞–Ω–∏–µ: –ù–µ–∫–æ—Ç–æ—Ä—ã–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã –≤ —Ç–µ–∫—É—â–µ–π –≤–µ—Ä—Å–∏–∏ SAMe:\n",
      "   ‚Ä¢ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–æ–≤ (–ì–û–°–¢, DIN, ISO)\n",
      "   ‚Ä¢ –°–ø–µ—Ü–∏–∞–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–æ–º–µ—Ä–æ–≤ –º–æ–¥–µ–ª–µ–π\n",
      "   ‚Ä¢ –†–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –∏–∑–º–µ—Ä–µ–Ω–∏–π\n",
      "   –≠—Ç–∏ —Ñ—É–Ω–∫—Ü–∏–∏ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω—ã –≤ —É–ª—É—á—à–µ–Ω–Ω–æ–π –ø—Ä–æ—Å—Ç–æ–π –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–µ.\n"
     ]
    }
   ],
   "source": [
    "# –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –¥–ª—è —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–π –Ω–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä—ã\n",
    "print(\"\\n‚öôÔ∏è –°–æ–∑–¥–∞–Ω–∏–µ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π...\")\n",
    "\n",
    "# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ–≥–æ —Å–æ–∑–¥–∞–Ω–∏—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤\n",
    "def create_safe_config(config_class, **kwargs):\n",
    "    \"\"\"\n",
    "    –ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ —Å–æ–∑–¥–∞–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –Ω–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤\n",
    "    –û—Å–Ω–æ–≤–∞–Ω–æ –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–∞—Ö –∏–∑ SAMe —Å–∏—Å—Ç–µ–º—ã\n",
    "    \"\"\"\n",
    "    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–ª–∞—Å—Å–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏\n",
    "    # –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–∞–ª—å–Ω–æ–π —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ SAMe\n",
    "    supported_params = {\n",
    "        'CleaningConfig': {\n",
    "            'remove_html', 'remove_special_chars', 'remove_extra_spaces', \n",
    "            'remove_numbers', 'preserve_technical_terms', 'custom_patterns'\n",
    "        },\n",
    "        'NormalizerConfig': {\n",
    "            'standardize_units', 'normalize_abbreviations', 'unify_technical_terms',\n",
    "            'remove_brand_names', 'standardize_numbers'\n",
    "        },\n",
    "        'LemmatizerConfig': {\n",
    "            'model_name', 'preserve_technical_terms', 'custom_stopwords',\n",
    "            'min_token_length', 'preserve_numbers'\n",
    "        },\n",
    "        'PreprocessorConfig': {\n",
    "            'cleaning_config', 'lemmatizer_config', 'normalizer_config',\n",
    "            'save_intermediate_steps', 'batch_size'\n",
    "        },\n",
    "        'FuzzySearchConfig': {\n",
    "            'tfidf_max_features', 'tfidf_ngram_range', 'tfidf_min_df', 'tfidf_max_df',\n",
    "            'cosine_threshold', 'fuzzy_threshold', 'levenshtein_threshold', 'similarity_threshold',\n",
    "            'cosine_weight', 'fuzzy_weight', 'levenshtein_weight',\n",
    "            'max_candidates', 'top_k_results', 'max_results', 'use_stemming'\n",
    "        },\n",
    "        'SemanticSearchConfig': {\n",
    "            'model_name', 'embedding_dim', 'index_type', 'nlist', 'nprobe',\n",
    "            'similarity_threshold', 'top_k_results', 'max_results',\n",
    "            'batch_size', 'normalize_embeddings', 'use_gpu'\n",
    "        },\n",
    "        'HybridSearchConfig': {\n",
    "            'fuzzy_config', 'semantic_config', 'fuzzy_weight', 'semantic_weight',\n",
    "            'min_fuzzy_score', 'min_semantic_score', 'max_candidates_per_method',\n",
    "            'final_top_k', 'max_results', 'similarity_threshold', 'combination_strategy',\n",
    "            'enable_parallel_search', 'max_workers'\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    config_name = config_class.__name__\n",
    "    \n",
    "    if config_name in supported_params:\n",
    "        # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã\n",
    "        safe_kwargs = {k: v for k, v in kwargs.items() \n",
    "                      if k in supported_params[config_name]}\n",
    "        \n",
    "        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã\n",
    "        filtered_out = set(kwargs.keys()) - set(safe_kwargs.keys())\n",
    "        if filtered_out:\n",
    "            print(f\"‚ö†Ô∏è {config_name}: –ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω—ã: {filtered_out}\")\n",
    "    else:\n",
    "        safe_kwargs = kwargs\n",
    "    \n",
    "    try:\n",
    "        return config_class(**safe_kwargs)\n",
    "    except TypeError as e:\n",
    "        print(f\"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è {config_name}: {e}\")\n",
    "        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é\n",
    "        return config_class()\n",
    "\n",
    "# –°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π —Å —Ç–æ–ª—å–∫–æ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏\n",
    "print(\"üìã –°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π —Å –ø—Ä–æ–≤–µ—Ä–µ–Ω–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏...\")\n",
    "\n",
    "# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è –æ—á–∏—Å—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞ (—Ç–æ–ª—å–∫–æ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã)\n",
    "cleaning_config = create_safe_config(\n",
    "    CleaningConfig,\n",
    "    remove_html=True,\n",
    "    remove_special_chars=True,\n",
    "    remove_extra_spaces=True,\n",
    "    remove_numbers=False,  # –°–æ—Ö—Ä–∞–Ω—è–µ–º —á–∏—Å–ª–∞ –¥–ª—è —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫\n",
    "    preserve_technical_terms=True,  # –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è –≤ SAMe\n",
    "    custom_patterns=[]  # –ü—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫ –¥–ª—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤\n",
    ")\n",
    "\n",
    "# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ (—Ç–æ–ª—å–∫–æ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã)\n",
    "normalizer_config = create_safe_config(\n",
    "    NormalizerConfig,\n",
    "    standardize_units=True,      # –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è - –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –µ–¥–∏–Ω–∏—Ü –∏–∑–º–µ—Ä–µ–Ω–∏—è\n",
    "    normalize_abbreviations=True, # –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è - –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Å–æ–∫—Ä–∞—â–µ–Ω–∏–π\n",
    "    unify_technical_terms=True,  # –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è - —É–Ω–∏—Ñ–∏–∫–∞—Ü–∏—è —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤\n",
    "    remove_brand_names=False,    # –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è - —Å–æ—Ö—Ä–∞–Ω—è–µ–º –±—Ä–µ–Ω–¥—ã\n",
    "    standardize_numbers=True     # –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è - —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏—è —á–∏—Å–µ–ª\n",
    ")\n",
    "\n",
    "# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è –ª–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏–∏ (—Ç–æ–ª—å–∫–æ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã)\n",
    "lemmatizer_config = create_safe_config(\n",
    "    LemmatizerConfig,\n",
    "    model_name=spacy_model,\n",
    "    preserve_technical_terms=True,  # –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è\n",
    "    min_token_length=2,            # –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è\n",
    "    preserve_numbers=True,         # –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è\n",
    "    custom_stopwords=set()         # –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è (–ø—É—Å—Ç–æ–µ –º–Ω–æ–∂–µ—Å—Ç–≤–æ)\n",
    ")\n",
    "\n",
    "print(\"‚úÖ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ —Å–æ–∑–¥–∞–Ω—ã —Å —Å–æ–≤–º–µ—Å—Ç–∏–º—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏\")\n",
    "print(\"\\nüí° –ü—Ä–∏–º–µ—á–∞–Ω–∏–µ: –ù–µ–∫–æ—Ç–æ—Ä—ã–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã –≤ —Ç–µ–∫—É—â–µ–π –≤–µ—Ä—Å–∏–∏ SAMe:\")\n",
    "print(\"   ‚Ä¢ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–æ–≤ (–ì–û–°–¢, DIN, ISO)\")\n",
    "print(\"   ‚Ä¢ –°–ø–µ—Ü–∏–∞–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–æ–º–µ—Ä–æ–≤ –º–æ–¥–µ–ª–µ–π\")\n",
    "print(\"   ‚Ä¢ –†–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –∏–∑–º–µ—Ä–µ–Ω–∏–π\")\n",
    "print(\"   –≠—Ç–∏ —Ñ—É–Ω–∫—Ü–∏–∏ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω—ã –≤ —É–ª—É—á—à–µ–Ω–Ω–æ–π –ø—Ä–æ—Å—Ç–æ–π –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–µ.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîß –°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏...\n",
      "‚úÖ TextCleaner —Å–æ–∑–¥–∞–Ω —É—Å–ø–µ—à–Ω–æ\n",
      "‚úÖ TextNormalizer —Å–æ–∑–¥–∞–Ω —É—Å–ø–µ—à–Ω–æ\n",
      "‚úÖ Lemmatizer —Å–æ–∑–¥–∞–Ω —É—Å–ø–µ—à–Ω–æ\n",
      "‚úÖ TextPreprocessor —Å–æ–∑–¥–∞–Ω —É—Å–ø–µ—à–Ω–æ\n",
      "üìã –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –º–µ—Ç–æ–¥: preprocess_text\n",
      "\n",
      "üìä –°—Ç–∞—Ç—É—Å –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏:\n",
      "   TextCleaner: ‚úÖ\n",
      "   TextNormalizer: ‚úÖ\n",
      "   Lemmatizer: ‚úÖ\n",
      "   TextPreprocessor: ‚úÖ\n",
      "‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø–æ–ª–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å —É–º–Ω—ã–º fallback\n",
      "\n",
      "üîß –°–∏—Å—Ç–µ–º–∞ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏ –≥–æ—Ç–æ–≤–∞:\n",
      "   –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è: final_preprocess_function\n",
      "   Fallback —Ñ—É–Ω–∫—Ü–∏—è: enhanced_simple_preprocess\n",
      "   –°–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å: simple_preprocess (–¥–ª—è —Å—Ç–∞—Ä–æ–≥–æ –∫–æ–¥–∞)\n",
      "\n",
      "üìã –í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ —Å–∏—Å—Ç–µ–º—ã –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏:\n",
      "‚úÖ –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ SAMe:\n",
      "   ‚Ä¢ –û—á–∏—Å—Ç–∫–∞ HTML –∏ —Å–ø–µ—Ü—Å–∏–º–≤–æ–ª–æ–≤\n",
      "   ‚Ä¢ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤\n",
      "   ‚Ä¢ –°—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏—è –µ–¥–∏–Ω–∏—Ü –∏–∑–º–µ—Ä–µ–Ω–∏—è\n",
      "   ‚Ä¢ –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Å–æ–∫—Ä–∞—â–µ–Ω–∏–π\n",
      "   ‚Ä¢ –£–Ω–∏—Ñ–∏–∫–∞—Ü–∏—è —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤\n",
      "   ‚Ä¢ –õ–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏—è —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º —á–∏—Å–µ–ª\n",
      "   ‚Ä¢ –ü–∞–∫–µ—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞\n",
      "\n",
      "‚ö†Ô∏è –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è —Ç–µ–∫—É—â–µ–π –≤–µ—Ä—Å–∏–∏ SAMe:\n",
      "   ‚Ä¢ –ù–µ—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Å—Ç–∞–Ω–¥–∞—Ä—Ç–æ–≤ (–ì–û–°–¢, DIN, ISO)\n",
      "   ‚Ä¢ –ù–µ—Ç —Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ –Ω–æ–º–µ—Ä–æ–≤ –º–æ–¥–µ–ª–µ–π\n",
      "   ‚Ä¢ –ù–µ—Ç —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–π —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –∏–∑–º–µ—Ä–µ–Ω–∏–π\n",
      "   ‚Ä¢ –û–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ —Å—Ç–æ–ø-—Å–ª–æ–≤\n",
      "\n",
      "üí° –ö–æ–º–ø–µ–Ω—Å–∞—Ü–∏—è –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π:\n",
      "   ‚Ä¢ –£–ª—É—á—à–µ–Ω–Ω–∞—è –ø—Ä–æ—Å—Ç–∞—è –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –≤–∫–ª—é—á–∞–µ—Ç –≤—Å–µ –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏\n",
      "   ‚Ä¢ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π fallback –ø—Ä–∏ –æ—à–∏–±–∫–∞—Ö\n",
      "   ‚Ä¢ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ —á–µ—Ä–µ–∑ regex-–ø–∞—Ç—Ç–µ—Ä–Ω—ã\n",
      "   ‚Ä¢ –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö —Å–æ–∫—Ä–∞—â–µ–Ω–∏–π\n"
     ]
    }
   ],
   "source": [
    "# –°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫\n",
    "print(\"\\nüîß –°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏...\")\n",
    "\n",
    "# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö\n",
    "text_cleaner = None\n",
    "text_normalizer = None\n",
    "lemmatizer = None\n",
    "preprocessor = None\n",
    "preprocessing_errors = []\n",
    "\n",
    "# –°–æ–∑–¥–∞–Ω–∏–µ –æ—á–∏—Å—Ç–∏—Ç–µ–ª—è —Ç–µ–∫—Å—Ç–∞\n",
    "try:\n",
    "    text_cleaner = TextCleaner(cleaning_config)\n",
    "    print(\"‚úÖ TextCleaner —Å–æ–∑–¥–∞–Ω —É—Å–ø–µ—à–Ω–æ\")\n",
    "except Exception as e:\n",
    "    error_msg = f\"TextCleaner: {str(e)}\"\n",
    "    preprocessing_errors.append(error_msg)\n",
    "    print(f\"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è TextCleaner: {e}\")\n",
    "\n",
    "# –°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ç–æ—Ä–∞\n",
    "try:\n",
    "    text_normalizer = TextNormalizer(normalizer_config)\n",
    "    print(\"‚úÖ TextNormalizer —Å–æ–∑–¥–∞–Ω —É—Å–ø–µ—à–Ω–æ\")\n",
    "except Exception as e:\n",
    "    error_msg = f\"TextNormalizer: {str(e)}\"\n",
    "    preprocessing_errors.append(error_msg)\n",
    "    print(f\"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è TextNormalizer: {e}\")\n",
    "\n",
    "# –°–æ–∑–¥–∞–Ω–∏–µ –ª–µ–º–º–∞—Ç–∏–∑–∞—Ç–æ—Ä–∞ (—Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ SpaCy –¥–æ—Å—Ç—É–ø–µ–Ω)\n",
    "if spacy_available:\n",
    "    try:\n",
    "        lemmatizer = Lemmatizer(lemmatizer_config)\n",
    "        print(\"‚úÖ Lemmatizer —Å–æ–∑–¥–∞–Ω —É—Å–ø–µ—à–Ω–æ\")\n",
    "    except Exception as e:\n",
    "        error_msg = f\"Lemmatizer: {str(e)}\"\n",
    "        preprocessing_errors.append(error_msg)\n",
    "        print(f\"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è Lemmatizer: {e}\")\n",
    "        spacy_available = False  # –û—Ç–∫–ª—é—á–∞–µ–º SpaCy –µ—Å–ª–∏ –ª–µ–º–º–∞—Ç–∏–∑–∞—Ç–æ—Ä –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Lemmatizer –ø—Ä–æ–ø—É—â–µ–Ω (SpaCy –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω)\")\n",
    "\n",
    "# –°–æ–∑–¥–∞–Ω–∏–µ –ø–æ–ª–Ω–æ–≥–æ –ø–∞–π–ø–ª–∞–π–Ω–∞\n",
    "if any([text_cleaner, text_normalizer, lemmatizer]):\n",
    "    try:\n",
    "        # –°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞ —Å–æ–≥–ª–∞—Å–Ω–æ —Ä–µ–∞–ª—å–Ω–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–µ SAMe\n",
    "        # PreprocessorConfig –ø—Ä–∏–Ω–∏–º–∞–µ—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤, –∞ –Ω–µ –±—É–ª–µ–≤—ã —Ñ–ª–∞–≥–∏\n",
    "        preprocessor_config = create_safe_config(\n",
    "            PreprocessorConfig,\n",
    "            cleaning_config=cleaning_config if text_cleaner else None,\n",
    "            normalizer_config=normalizer_config if text_normalizer else None,\n",
    "            lemmatizer_config=lemmatizer_config if lemmatizer else None,\n",
    "            save_intermediate_steps=True,  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã\n",
    "            batch_size=1000               # –†–∞–∑–º–µ—Ä batch –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –±–æ–ª—å—à–∏—Ö –¥–∞—Ç–∞—Å–µ—Ç–æ–≤\n",
    "            # –£–¥–∞–ª–µ–Ω—ã –Ω–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã: enable_cleaning, enable_normalization,\n",
    "            # enable_lemmatization, show_progress, handle_errors_gracefully, preserve_original\n",
    "        )\n",
    "        \n",
    "        preprocessor = TextPreprocessor(preprocessor_config)\n",
    "        print(\"‚úÖ TextPreprocessor —Å–æ–∑–¥–∞–Ω —É—Å–ø–µ—à–Ω–æ\")\n",
    "        \n",
    "        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –º–µ—Ç–æ–¥–∞ process_text vs preprocess_text\n",
    "        if hasattr(preprocessor, 'preprocess_text'):\n",
    "            preprocess_method_name = 'preprocess_text'\n",
    "        elif hasattr(preprocessor, 'process_text'):\n",
    "            preprocess_method_name = 'process_text'\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è –ù–µ –Ω–∞–π–¥–µ–Ω —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –º–µ—Ç–æ–¥ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏\")\n",
    "            preprocess_method_name = None\n",
    "        \n",
    "        print(f\"üìã –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –º–µ—Ç–æ–¥: {preprocess_method_name}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        error_msg = f\"TextPreprocessor: {str(e)}\"\n",
    "        preprocessing_errors.append(error_msg)\n",
    "        print(f\"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è TextPreprocessor: {e}\")\n",
    "        preprocessor = None\n",
    "\n",
    "# –ò—Ç–æ–≥–æ–≤—ã–π —Å—Ç–∞—Ç—É—Å\n",
    "print(f\"\\nüìä –°—Ç–∞—Ç—É—Å –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏:\")\n",
    "print(f\"   TextCleaner: {'‚úÖ' if text_cleaner else '‚ùå'}\")\n",
    "print(f\"   TextNormalizer: {'‚úÖ' if text_normalizer else '‚ùå'}\")\n",
    "print(f\"   Lemmatizer: {'‚úÖ' if lemmatizer else '‚ùå'}\")\n",
    "print(f\"   TextPreprocessor: {'‚úÖ' if preprocessor else '‚ùå'}\")\n",
    "\n",
    "if preprocessing_errors:\n",
    "    print(f\"\\n‚ö†Ô∏è –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –æ—à–∏–±–∫–∏ ({len(preprocessing_errors)}):\")\n",
    "    for error in preprocessing_errors:\n",
    "        print(f\"   ‚Ä¢ {error}\")\n",
    "    print(f\"\\nüí° –ë—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∞ —É–ø—Ä–æ—â–µ–Ω–Ω–∞—è –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞\")\n",
    "\n",
    "# –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—É—é —Ñ—É–Ω–∫—Ü–∏—é –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º–∏ –º–µ—Ç–æ–¥–∞–º–∏\n",
    "if preprocessor:\n",
    "    def final_preprocess_function(text):\n",
    "        try:\n",
    "            # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ –º–µ—Ç–æ–¥—ã –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –≤–µ—Ä—Å–∏–∏ SAMe\n",
    "            if hasattr(preprocessor, 'preprocess_text'):\n",
    "                result = preprocessor.preprocess_text(str(text))\n",
    "                # –†–µ–∑—É–ª—å—Ç–∞—Ç –º–æ–∂–µ—Ç –±—ã—Ç—å —Å–ª–æ–≤–∞—Ä–µ–º —Å —Ä–∞–∑–Ω—ã–º–∏ –∫–ª—é—á–∞–º–∏\n",
    "                if isinstance(result, dict):\n",
    "                    return result.get('final_normalized', \n",
    "                           result.get('final_text',\n",
    "                           result.get('lemmatized', str(text))))\n",
    "                else:\n",
    "                    return str(result)\n",
    "            elif hasattr(preprocessor, 'process_text'):\n",
    "                result = preprocessor.process_text(str(text))\n",
    "                if isinstance(result, dict):\n",
    "                    return result.get('final_text', str(text))\n",
    "                else:\n",
    "                    return str(result)\n",
    "            else:\n",
    "                # Fallback –µ—Å–ª–∏ –º–µ—Ç–æ–¥—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã\n",
    "                return enhanced_simple_preprocess(text)\n",
    "        except Exception as e:\n",
    "            # –í —Å–ª—É—á–∞–µ –ª—é–±–æ–π –æ—à–∏–±–∫–∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º —É–ø—Ä–æ—â–µ–Ω–Ω—É—é –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫—É\n",
    "            return enhanced_simple_preprocess(text)\n",
    "    \n",
    "    print(\"‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø–æ–ª–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å —É–º–Ω—ã–º fallback\")\n",
    "else:\n",
    "    final_preprocess_function = enhanced_simple_preprocess\n",
    "    print(\"‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —É–ª—É—á—à–µ–Ω–Ω–∞—è —É–ø—Ä–æ—â–µ–Ω–Ω–∞—è –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞\")\n",
    "\n",
    "# –î–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏\n",
    "simple_preprocess = enhanced_simple_preprocess\n",
    "\n",
    "print(f\"\\nüîß –°–∏—Å—Ç–µ–º–∞ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏ –≥–æ—Ç–æ–≤–∞:\")\n",
    "print(f\"   –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è: final_preprocess_function\")\n",
    "print(f\"   Fallback —Ñ—É–Ω–∫—Ü–∏—è: enhanced_simple_preprocess\")\n",
    "print(f\"   –°–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å: simple_preprocess (–¥–ª—è —Å—Ç–∞—Ä–æ–≥–æ –∫–æ–¥–∞)\")\n",
    "\n",
    "# –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π –∏ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π\n",
    "print(f\"\\nüìã –í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ —Å–∏—Å—Ç–µ–º—ã –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏:\")\n",
    "print(f\"‚úÖ –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ SAMe:\")\n",
    "print(f\"   ‚Ä¢ –û—á–∏—Å—Ç–∫–∞ HTML –∏ —Å–ø–µ—Ü—Å–∏–º–≤–æ–ª–æ–≤\")\n",
    "print(f\"   ‚Ä¢ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤\")\n",
    "print(f\"   ‚Ä¢ –°—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏—è –µ–¥–∏–Ω–∏—Ü –∏–∑–º–µ—Ä–µ–Ω–∏—è\")\n",
    "print(f\"   ‚Ä¢ –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Å–æ–∫—Ä–∞—â–µ–Ω–∏–π\")\n",
    "print(f\"   ‚Ä¢ –£–Ω–∏—Ñ–∏–∫–∞—Ü–∏—è —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤\")\n",
    "print(f\"   ‚Ä¢ –õ–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏—è —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º —á–∏—Å–µ–ª\")\n",
    "print(f\"   ‚Ä¢ –ü–∞–∫–µ—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞\")\n",
    "\n",
    "print(f\"\\n‚ö†Ô∏è –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è —Ç–µ–∫—É—â–µ–π –≤–µ—Ä—Å–∏–∏ SAMe:\")\n",
    "print(f\"   ‚Ä¢ –ù–µ—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Å—Ç–∞–Ω–¥–∞—Ä—Ç–æ–≤ (–ì–û–°–¢, DIN, ISO)\")\n",
    "print(f\"   ‚Ä¢ –ù–µ—Ç —Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ –Ω–æ–º–µ—Ä–æ–≤ –º–æ–¥–µ–ª–µ–π\")\n",
    "print(f\"   ‚Ä¢ –ù–µ—Ç —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–π —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –∏–∑–º–µ—Ä–µ–Ω–∏–π\")\n",
    "print(f\"   ‚Ä¢ –û–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ —Å—Ç–æ–ø-—Å–ª–æ–≤\")\n",
    "\n",
    "print(f\"\\nüí° –ö–æ–º–ø–µ–Ω—Å–∞—Ü–∏—è –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π:\")\n",
    "print(f\"   ‚Ä¢ –£–ª—É—á—à–µ–Ω–Ω–∞—è –ø—Ä–æ—Å—Ç–∞—è –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –≤–∫–ª—é—á–∞–µ—Ç –≤—Å–µ –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏\")\n",
    "print(f\"   ‚Ä¢ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π fallback –ø—Ä–∏ –æ—à–∏–±–∫–∞—Ö\")\n",
    "print(f\"   ‚Ä¢ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ —á–µ—Ä–µ–∑ regex-–ø–∞—Ç—Ç–µ—Ä–Ω—ã\")\n",
    "print(f\"   ‚Ä¢ –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö —Å–æ–∫—Ä–∞—â–µ–Ω–∏–π\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ –ë–µ–∑–æ–ø–∞—Å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è final_preprocess_function —Å–æ–∑–¥–∞–Ω–∞\n"
     ]
    }
   ],
   "source": [
    "def create_safe_final_preprocess_function():\n",
    "    \"\"\"–°–æ–∑–¥–∞–µ—Ç –±–µ–∑–æ–ø–∞—Å–Ω—É—é —Å–∏–Ω—Ö—Ä–æ–Ω–Ω—É—é —Ñ—É–Ω–∫—Ü–∏—é –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏\"\"\"\n",
    "    import re\n",
    "    \n",
    "    def safe_final_preprocess(text):\n",
    "        \"\"\"–ë–µ–∑–æ–ø–∞—Å–Ω–∞—è –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –±–µ–∑ async –ø—Ä–æ–±–ª–µ–º\"\"\"\n",
    "        try:\n",
    "            text = str(text).lower().strip()\n",
    "            \n",
    "            # –ë–∞–∑–æ–≤–∞—è –æ—á–∏—Å—Ç–∫–∞ –∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è\n",
    "            text = re.sub(r'\\s+', ' ', text)  \n",
    "            text = re.sub(r'[^\\w\\s\\-\\.\\,\\(\\)√ó¬∞]', '', text)  \n",
    "            \n",
    "            return text.strip()\n",
    "        except Exception:\n",
    "            return str(text).lower().strip()\n",
    "    \n",
    "    return safe_final_preprocess\n",
    "\n",
    "final_preprocess_function = create_safe_final_preprocess_function()\n",
    "print(\"‚úÖ –ë–µ–∑–æ–ø–∞—Å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è final_preprocess_function —Å–æ–∑–¥–∞–Ω–∞\")\n",
    "\n",
    "if 'enhanced_simple_preprocess' not in globals():\n",
    "    enhanced_simple_preprocess = final_preprocess_function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üß™ –í–∞–ª–∏–¥–∞—Ü–∏—è —Å–∏—Å—Ç–µ–º—ã –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏...\n",
      "\n",
      "üìù –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ 7 –ø—Ä–∏–º–µ—Ä–∞—Ö:\n",
      "================================================================================\n",
      "\n",
      "1. –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç:\n",
      "   –ë–æ–ª—Ç –ú10√ó50 –ì–û–°–¢ 7798-70 –æ—Ü–∏–Ω–∫–æ–≤–∞–Ω–Ω—ã–π —Å —à–µ—Å—Ç–∏–≥—Ä–∞–Ω–Ω–æ–π –≥–æ–ª–æ–≤–∫–æ–π\n",
      "   ‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π: –±–æ–ª—Ç –º10√ó50 –≥–æ—Å—Ç 7798-70 –æ—Ü–∏–Ω–∫–æ–≤–∞–Ω–Ω—ã–π —Å —à–µ—Å—Ç–∏–≥—Ä–∞–Ω–Ω–æ–π –≥–æ–ª–æ–≤–∫–æ–π\n",
      "   ‚è±Ô∏è  –í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: 0.0002 —Å–µ–∫\n",
      "\n",
      "2. –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç:\n",
      "   –î–≤–∏–≥–∞—Ç–µ–ª—å –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π 4–∫–í—Ç 1500 –æ–±/–º–∏–Ω 380–í IP54\n",
      "   ‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π: –¥–≤–∏–≥–∞—Ç–µ–ª—å –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π 4–∫–≤—Ç 1500 –æ–±–º–∏–Ω 380–≤ ip54\n",
      "   ‚è±Ô∏è  –í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: 0.0000 —Å–µ–∫\n",
      "\n",
      "3. –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç:\n",
      "   –ù–∞—Å–æ—Å —Ü–µ–Ω—Ç—Ä–æ–±–µ–∂–Ω—ã–π Q=50–º¬≥/—á H=32–º N=7.5–∫–í—Ç\n",
      "   ‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π: –Ω–∞—Å–æ—Å —Ü–µ–Ω—Ç—Ä–æ–±–µ–∂–Ω—ã–π q50–º¬≥—á h32–º n7.5–∫–≤—Ç\n",
      "   ‚è±Ô∏è  –í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: 0.0000 —Å–µ–∫\n",
      "\n",
      "4. –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç:\n",
      "   –ö–∞–±–µ–ª—å –í–í–ì–Ω–≥-LS 3√ó2.5 –º–º¬≤ 0.66/1–∫–í\n",
      "   ‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π: –∫–∞–±–µ–ª—å –≤–≤–≥–Ω–≥-ls 3√ó2.5 –º–º¬≤ 0.661–∫–≤\n",
      "   ‚è±Ô∏è  –í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: 0.0000 —Å–µ–∫\n",
      "\n",
      "5. –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç:\n",
      "   –ü–æ–¥—à–∏–ø–Ω–∏–∫ —à–∞—Ä–∏–∫–æ–≤—ã–π 6205-2RS —Ä–∞–∑–º–µ—Ä 25√ó52√ó15–º–º\n",
      "   ‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π: –ø–æ–¥—à–∏–ø–Ω–∏–∫ —à–∞—Ä–∏–∫–æ–≤—ã–π 6205-2rs —Ä–∞–∑–º–µ—Ä 25√ó52√ó15–º–º\n",
      "   ‚è±Ô∏è  –í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: 0.0000 —Å–µ–∫\n",
      "\n",
      "6. –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç:\n",
      "   –ö–ª–∞–ø–∞–Ω —à–∞—Ä–æ–≤–æ–π DN50 PN16 –Ω–µ—Ä–∂. —Å—Ç–∞–ª—å 316L\n",
      "   ‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π: –∫–ª–∞–ø–∞–Ω —à–∞—Ä–æ–≤–æ–π dn50 pn16 –Ω–µ—Ä–∂. —Å—Ç–∞–ª—å 316l\n",
      "   ‚è±Ô∏è  –í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: 0.0000 —Å–µ–∫\n",
      "\n",
      "7. –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç:\n",
      "   –†–µ–¥—É–∫—Ç–æ—Ä —á–µ—Ä–≤—è—á–Ω—ã–π i=40 –ú–Ω–æ–º=1.5–∫–í—Ç\n",
      "   ‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π: —Ä–µ–¥—É–∫—Ç–æ—Ä —á–µ—Ä–≤—è—á–Ω—ã–π i40 –º–Ω–æ–º1.5–∫–≤—Ç\n",
      "   ‚è±Ô∏è  –í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: 0.0000 —Å–µ–∫\n",
      "\n",
      "\n",
      "üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤–∞–ª–∏–¥–∞—Ü–∏–∏:\n",
      "==================================================\n",
      "‚úÖ –£—Å–ø–µ—à–Ω—ã—Ö —Ç–µ—Å—Ç–æ–≤: 7/7 (100.0%)\n",
      "‚è±Ô∏è  –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: 0.0000 —Å–µ–∫\n",
      "üéØ –°—Ä–µ–¥–Ω–∏–π –±–∞–ª–ª –∫–∞—á–µ—Å—Ç–≤–∞: 3.0/3\n",
      "\n",
      "üéâ –í—Å–µ —Ç–µ—Å—Ç—ã –ø—Ä–æ–π–¥–µ–Ω—ã —É—Å–ø–µ—à–Ω–æ! –°–∏—Å—Ç–µ–º–∞ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏ –≥–æ—Ç–æ–≤–∞ –∫ —Ä–∞–±–æ—Ç–µ.\n",
      "\n",
      "‚úÖ –í–∞–ª–∏–¥–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –°–∏—Å—Ç–µ–º–∞ –≥–æ—Ç–æ–≤–∞ –∫ –æ–±—Ä–∞–±–æ—Ç–∫–µ –¥–∞–Ω–Ω—ã—Ö.\n"
     ]
    }
   ],
   "source": [
    "# –í–∞–ª–∏–¥–∞—Ü–∏—è –∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–∏—Å—Ç–µ–º—ã –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏\n",
    "print(\"\\nüß™ –í–∞–ª–∏–¥–∞—Ü–∏—è —Å–∏—Å—Ç–µ–º—ã –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏...\")\n",
    "\n",
    "# –¢–µ—Å—Ç–æ–≤—ã–µ –ø—Ä–∏–º–µ—Ä—ã —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–π\n",
    "test_samples = [\n",
    "    \"–ë–æ–ª—Ç –ú10√ó50 –ì–û–°–¢ 7798-70 –æ—Ü–∏–Ω–∫–æ–≤–∞–Ω–Ω—ã–π —Å —à–µ—Å—Ç–∏–≥—Ä–∞–Ω–Ω–æ–π –≥–æ–ª–æ–≤–∫–æ–π\",\n",
    "    \"–î–≤–∏–≥–∞—Ç–µ–ª—å –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π 4–∫–í—Ç 1500 –æ–±/–º–∏–Ω 380–í IP54\",\n",
    "    \"–ù–∞—Å–æ—Å —Ü–µ–Ω—Ç—Ä–æ–±–µ–∂–Ω—ã–π Q=50–º¬≥/—á H=32–º N=7.5–∫–í—Ç\",\n",
    "    \"–ö–∞–±–µ–ª—å –í–í–ì–Ω–≥-LS 3√ó2.5 –º–º¬≤ 0.66/1–∫–í\",\n",
    "    \"–ü–æ–¥—à–∏–ø–Ω–∏–∫ —à–∞—Ä–∏–∫–æ–≤—ã–π 6205-2RS —Ä–∞–∑–º–µ—Ä 25√ó52√ó15–º–º\",\n",
    "    \"–ö–ª–∞–ø–∞–Ω —à–∞—Ä–æ–≤–æ–π DN50 PN16 –Ω–µ—Ä–∂. —Å—Ç–∞–ª—å 316L\",\n",
    "    \"–†–µ–¥—É–∫—Ç–æ—Ä —á–µ—Ä–≤—è—á–Ω—ã–π i=40 –ú–Ω–æ–º=1.5–∫–í—Ç\"\n",
    "]\n",
    "\n",
    "print(f\"\\nüìù –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ {len(test_samples)} –ø—Ä–∏–º–µ—Ä–∞—Ö:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "validation_results = []\n",
    "processing_times = []\n",
    "\n",
    "for i, sample in enumerate(test_samples, 1):\n",
    "    print(f\"\\n{i}. –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç:\")\n",
    "    print(f\"   {sample}\")\n",
    "    \n",
    "    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –æ—Å–Ω–æ–≤–Ω—É—é —Ñ—É–Ω–∫—Ü–∏—é –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏\n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        processed = final_preprocess_function(sample)\n",
    "        processing_time = time.time() - start_time\n",
    "        processing_times.append(processing_time)\n",
    "        \n",
    "        print(f\"   ‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π: {processed}\")\n",
    "        print(f\"   ‚è±Ô∏è  –í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {processing_time:.4f} —Å–µ–∫\")\n",
    "        \n",
    "        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞–±–æ—Ç–∫–∏\n",
    "        quality_score = 0\n",
    "        \n",
    "        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫\n",
    "        if re.search(r'\\d+', processed):  # –ß–∏—Å–ª–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã\n",
    "            quality_score += 1\n",
    "        if len(processed) > len(sample) * 0.5:  # –ù–µ —Å–ª–∏—à–∫–æ–º —Å–∏–ª—å–Ω–æ —Å–æ–∫—Ä–∞—â–µ–Ω\n",
    "            quality_score += 1\n",
    "        if processed.strip():  # –ù–µ –ø—É—Å—Ç–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç\n",
    "            quality_score += 1\n",
    "        \n",
    "        validation_results.append({\n",
    "            'original': sample,\n",
    "            'processed': processed,\n",
    "            'processing_time': processing_time,\n",
    "            'quality_score': quality_score,\n",
    "            'success': True\n",
    "        })\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {e}\")\n",
    "        validation_results.append({\n",
    "            'original': sample,\n",
    "            'processed': '',\n",
    "            'processing_time': 0,\n",
    "            'quality_score': 0,\n",
    "            'success': False,\n",
    "            'error': str(e)\n",
    "        })\n",
    "\n",
    "# –ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤–∞–ª–∏–¥–∞—Ü–∏–∏\n",
    "print(f\"\\n\\nüìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤–∞–ª–∏–¥–∞—Ü–∏–∏:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "successful_tests = sum(1 for r in validation_results if r['success'])\n",
    "avg_processing_time = np.mean(processing_times) if processing_times else 0\n",
    "avg_quality_score = np.mean([r['quality_score'] for r in validation_results])\n",
    "\n",
    "print(f\"‚úÖ –£—Å–ø–µ—à–Ω—ã—Ö —Ç–µ—Å—Ç–æ–≤: {successful_tests}/{len(test_samples)} ({successful_tests/len(test_samples)*100:.1f}%)\")\n",
    "print(f\"‚è±Ô∏è  –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {avg_processing_time:.4f} —Å–µ–∫\")\n",
    "print(f\"üéØ –°—Ä–µ–¥–Ω–∏–π –±–∞–ª–ª –∫–∞—á–µ—Å—Ç–≤–∞: {avg_quality_score:.1f}/3\")\n",
    "\n",
    "if successful_tests == len(test_samples):\n",
    "    print(f\"\\nüéâ –í—Å–µ —Ç–µ—Å—Ç—ã –ø—Ä–æ–π–¥–µ–Ω—ã —É—Å–ø–µ—à–Ω–æ! –°–∏—Å—Ç–µ–º–∞ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏ –≥–æ—Ç–æ–≤–∞ –∫ —Ä–∞–±–æ—Ç–µ.\")\n",
    "elif successful_tests > len(test_samples) * 0.8:\n",
    "    print(f\"\\n‚ö†Ô∏è –ë–æ–ª—å—à–∏–Ω—Å—Ç–≤–æ —Ç–µ—Å—Ç–æ–≤ –ø—Ä–æ–π–¥–µ–Ω–æ. –°–∏—Å—Ç–µ–º–∞ —Ä–∞–±–æ—Ç–æ—Å–ø–æ—Å–æ–±–Ω–∞ —Å –Ω–µ–∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã–º–∏ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è–º–∏.\")\n",
    "else:\n",
    "    print(f\"\\n‚ùå –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã —Å–µ—Ä—å–µ–∑–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã. –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ç–æ–ª—å–∫–æ —É–ø—Ä–æ—â–µ–Ω–Ω—É—é –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫—É.\")\n",
    "\n",
    "# –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏\n",
    "if avg_processing_time > 0.1 or avg_quality_score < 2 or not spacy_available or preprocessing_errors:\n",
    "    print(f\"\\nüí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:\")\n",
    "if avg_processing_time > 0.1:\n",
    "    print(f\"   ‚Ä¢ –í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤—ã—Å–æ–∫–æ–µ - —Ä–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ batch-–æ–±—Ä–∞–±–æ—Ç–∫—É –¥–ª—è –±–æ–ª—å—à–∏—Ö –¥–∞—Ç–∞—Å–µ—Ç–æ–≤\")\n",
    "if avg_quality_score < 2:\n",
    "    print(f\"   ‚Ä¢ –ù–∏–∑–∫–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞–±–æ—Ç–∫–∏ - –ø—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏\")\n",
    "if not spacy_available:\n",
    "    print(f\"   ‚Ä¢ –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ SpaCy –º–æ–¥–µ–ª—å –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞ –ª–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏–∏\")\n",
    "if preprocessing_errors:\n",
    "    print(f\"   ‚Ä¢ –û–±–Ω–æ–≤–∏—Ç–µ –º–æ–¥—É–ª–∏ SAMe –¥–ª—è –ø–æ–¥–¥–µ—Ä–∂–∫–∏ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã—Ö –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π\")\n",
    "\n",
    "print(f\"\\n‚úÖ –í–∞–ª–∏–¥–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –°–∏—Å—Ç–µ–º–∞ –≥–æ—Ç–æ–≤–∞ –∫ –æ–±—Ä–∞–±–æ—Ç–∫–µ –¥–∞–Ω–Ω—ã—Ö.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–π —Ç–æ–≤–∞—Ä–æ–≤ —Å –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ–º async –ø—Ä–æ–±–ª–µ–º—ã...\n",
      "‚úÖ –ë–µ–∑–æ–ø–∞—Å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–æ–∑–¥–∞–Ω–∞\n",
      "üìä –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º 5 –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–π...\n",
      "\n",
      "\n",
      "\n",
      "‚úÖ –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –∑–∞ 0.00 —Å–µ–∫—É–Ω–¥\n",
      "üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏:\n",
      "   –í—Å–µ–≥–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: 5\n",
      "   –ü–æ–ª–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞: 5\n",
      "   –£–ø—Ä–æ—â–µ–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞: 0\n",
      "   –û—à–∏–±–∫–∏: 0\n",
      "   –°—Ä–µ–¥–Ω—è—è —Å–∫–æ—Ä–æ—Å—Ç—å: 12292.8 –∑–∞–ø–∏—Å–µ–π/—Å–µ–∫\n",
      "   –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –Ω–∞ –∑–∞–ø–∏—Å—å: 0.01 –º—Å\n",
      "   –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç —Å–∂–∞—Ç–∏—è —Ç–µ–∫—Å—Ç–∞: 1.00\n",
      "\n",
      "üìù –ü—Ä–∏–º–µ—Ä—ã –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å –∞–Ω–∞–ª–∏–∑–æ–º:\n",
      "================================================================================\n",
      "1. –ò—Å—Ö–æ–¥–Ω—ã–π (35 —Å–∏–º–≤–æ–ª–æ–≤):\n",
      "   –ì–∞–π–∫–∞ –ú10 —à–µ—Å—Ç–∏–≥—Ä–∞–Ω–Ω–∞—è –ì–û–°–¢ 5915-70\n",
      "   –û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π (35 —Å–∏–º–≤–æ–ª–æ–≤):\n",
      "   –≥–∞–π–∫–∞ –º10 —à–µ—Å—Ç–∏–≥—Ä–∞–Ω–Ω–∞—è –≥–æ—Å—Ç 5915-70\n",
      "   üìã –ò–∑–º–µ–Ω–µ–Ω–∏—è: —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã —á–∏—Å–ª–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è\n",
      "\n",
      "2. –ò—Å—Ö–æ–¥–Ω—ã–π (43 —Å–∏–º–≤–æ–ª–æ–≤):\n",
      "   –ë–æ–ª—Ç —Å —à–µ—Å—Ç–∏–≥—Ä–∞–Ω–Ω–æ–π –≥–æ–ª–æ–≤–∫–æ–π –ú12√ó60 DIN 933\n",
      "   –û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π (43 —Å–∏–º–≤–æ–ª–æ–≤):\n",
      "   –±–æ–ª—Ç —Å —à–µ—Å—Ç–∏–≥—Ä–∞–Ω–Ω–æ–π –≥–æ–ª–æ–≤–∫–æ–π –º12√ó60 din 933\n",
      "   üìã –ò–∑–º–µ–Ω–µ–Ω–∏—è: —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã —á–∏—Å–ª–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è\n",
      "\n",
      "3. –ò—Å—Ö–æ–¥–Ω—ã–π (37 —Å–∏–º–≤–æ–ª–æ–≤):\n",
      "   –ë–æ–ª—Ç –ú10√ó50 –ì–û–°–¢ 7798-70 –æ—Ü–∏–Ω–∫–æ–≤–∞–Ω–Ω—ã–π\n",
      "   –û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π (37 —Å–∏–º–≤–æ–ª–æ–≤):\n",
      "   –±–æ–ª—Ç –º10√ó50 –≥–æ—Å—Ç 7798-70 –æ—Ü–∏–Ω–∫–æ–≤–∞–Ω–Ω—ã–π\n",
      "   üìã –ò–∑–º–µ–Ω–µ–Ω–∏—è: —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã —á–∏—Å–ª–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è\n",
      "\n",
      "\n",
      "üéØ –î–∞–Ω–Ω—ã–µ –≥–æ—Ç–æ–≤—ã –¥–ª—è –ø–æ–∏—Å–∫–∞ –∞–Ω–∞–ª–æ–≥–æ–≤!\n"
     ]
    }
   ],
   "source": [
    "print(\"üîÑ –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–π —Ç–æ–≤–∞—Ä–æ–≤ —Å –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ–º async –ø—Ä–æ–±–ª–µ–º—ã...\")\n",
    "\n",
    "# –°–æ–∑–¥–∞–µ–º –°–ò–ù–•–†–û–ù–ù–£–Æ —Ñ—É–Ω–∫—Ü–∏—é –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏\n",
    "def create_safe_preprocessor():\n",
    "    \"\"\"–°–æ–∑–¥–∞–µ—Ç –±–µ–∑–æ–ø–∞—Å–Ω—É—é —Å–∏–Ω—Ö—Ä–æ–Ω–Ω—É—é —Ñ—É–Ω–∫—Ü–∏—é –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏\"\"\"\n",
    "    import re\n",
    "    \n",
    "    def safe_preprocess(text):\n",
    "        \"\"\"–ë–µ–∑–æ–ø–∞—Å–Ω–∞—è –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –±–µ–∑ async\"\"\"\n",
    "        try:\n",
    "            text = str(text).lower().strip()\n",
    "            \n",
    "            # –ë–∞–∑–æ–≤–∞—è –æ—á–∏—Å—Ç–∫–∞\n",
    "            text = re.sub(r'\\s+', ' ', text)  # –ú–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø—Ä–æ–±–µ–ª—ã\n",
    "            text = re.sub(r'[^\\w\\s\\-\\.\\,\\(\\)√ó]', '', text)  # –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –Ω—É–∂–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã\n",
    "            \n",
    "            return text.strip()\n",
    "        except Exception:\n",
    "            return str(text).lower().strip()\n",
    "    \n",
    "    return safe_preprocess\n",
    "\n",
    "# –°–æ–∑–¥–∞–µ–º –±–µ–∑–æ–ø–∞—Å–Ω—É—é —Ñ—É–Ω–∫—Ü–∏—é –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏\n",
    "safe_preprocess_function = create_safe_preprocessor()\n",
    "print(\"‚úÖ –ë–µ–∑–æ–ø–∞—Å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–æ–∑–¥–∞–Ω–∞\")\n",
    "\n",
    "# –°–æ–∑–¥–∞–µ–º –∫–æ–ø–∏—é –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ä–∞–±–æ—Ç—ã\n",
    "processed_data = data.copy()\n",
    "\n",
    "# –û—á–∏—â–∞–µ–º –æ—Ç –ø—É—Å—Ç—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π\n",
    "initial_count = len(processed_data)\n",
    "processed_data = processed_data.dropna(subset=[main_name_column])\n",
    "cleaned_count = len(processed_data)\n",
    "\n",
    "if initial_count != cleaned_count:\n",
    "    print(f\"üßπ –£–¥–∞–ª–µ–Ω–æ –ø—É—Å—Ç—ã—Ö –∑–∞–ø–∏—Å–µ–π: {initial_count - cleaned_count}\")\n",
    "\n",
    "print(f\"üìä –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º {cleaned_count} –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–π...\")\n",
    "\n",
    "# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –¥–ª—è —Å–±–æ—Ä–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏\n",
    "processing_stats = {\n",
    "    'total_processed': 0,\n",
    "    'successful_full_processing': 0,\n",
    "    'fallback_processing': 0,\n",
    "    'errors': 0,\n",
    "    'processing_times': [],\n",
    "    'original_lengths': [],\n",
    "    'processed_lengths': []\n",
    "}\n",
    "\n",
    "processed_names = []\n",
    "batch_size = 1000\n",
    "start_time = time.time()\n",
    "print()\n",
    "\n",
    "# –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å –ø—Ä–æ–≥—Ä–µ—Å—Å–æ–º –∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π\n",
    "for idx, name in enumerate(processed_data[main_name_column]):\n",
    "    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å\n",
    "    if idx % batch_size == 0 and idx > 0:\n",
    "        elapsed = time.time() - start_time\n",
    "        rate = idx / elapsed\n",
    "        eta = (cleaned_count - idx) / rate if rate > 0 else 0\n",
    "        print(\n",
    "            f\"\\rüìà –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {idx}/{cleaned_count} ({idx/cleaned_count*100:.1f}%) | \"\n",
    "            f\"–°–∫–æ—Ä–æ—Å—Ç—å: {rate:.1f} –∑–∞–ø–∏—Å–µ–π/—Å–µ–∫ | ETA: {eta:.0f} —Å–µ–∫\",\n",
    "            end='', flush=True\n",
    "        )\n",
    "    \n",
    "    item_start_time = time.time()\n",
    "    original_length = len(str(name))\n",
    "    \n",
    "    try:\n",
    "        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ë–ï–ó–û–ü–ê–°–ù–£–Æ —Å–∏–Ω—Ö—Ä–æ–Ω–Ω—É—é —Ñ—É–Ω–∫—Ü–∏—é –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏\n",
    "        processed_name = safe_preprocess_function(name)\n",
    "        \n",
    "        # –í—Å–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å—á–∏—Ç–∞–µ–º —É—Å–ø–µ—à–Ω—ã–º–∏\n",
    "        processing_stats['successful_full_processing'] += 1\n",
    "        \n",
    "        processed_names.append(processed_name)\n",
    "        \n",
    "        # –°–æ–±–∏—Ä–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É\n",
    "        processing_time = time.time() - item_start_time\n",
    "        processing_stats['processing_times'].append(processing_time)\n",
    "        processing_stats['original_lengths'].append(original_length)\n",
    "        processing_stats['processed_lengths'].append(len(processed_name))\n",
    "        processing_stats['total_processed'] += 1\n",
    "        \n",
    "    except Exception as e:\n",
    "        # –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ - –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π —Ç–µ–∫—Å—Ç\n",
    "        processed_names.append(str(name).lower().strip())\n",
    "        processing_stats['errors'] += 1\n",
    "        \n",
    "        if processing_stats['errors'] <= 5:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ 5 –æ—à–∏–±–æ–∫\n",
    "            print(f\"‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–ø–∏—Å–∏ {idx}: {e}\")\n",
    "\n",
    "print()\n",
    "\n",
    "# –î–æ–±–∞–≤–ª—è–µ–º –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ\n",
    "processed_data['processed_name'] = processed_names\n",
    "\n",
    "# –§–∏–Ω–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞\n",
    "total_time = time.time() - start_time\n",
    "avg_processing_time = np.mean(processing_stats['processing_times']) if processing_stats['processing_times'] else 0\n",
    "avg_original_length = np.mean(processing_stats['original_lengths'])\n",
    "avg_processed_length = np.mean(processing_stats['processed_lengths'])\n",
    "compression_ratio = avg_processed_length / avg_original_length if avg_original_length > 0 else 1\n",
    "\n",
    "print(f\"\\n‚úÖ –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –∑–∞ {total_time:.2f} —Å–µ–∫—É–Ω–¥\")\n",
    "print(f\"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏:\")\n",
    "print(f\"   –í—Å–µ–≥–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {processing_stats['total_processed']}\")\n",
    "print(f\"   –ü–æ–ª–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞: {processing_stats['successful_full_processing']}\")\n",
    "print(f\"   –£–ø—Ä–æ—â–µ–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞: {processing_stats['fallback_processing']}\")\n",
    "print(f\"   –û—à–∏–±–∫–∏: {processing_stats['errors']}\")\n",
    "print(f\"   –°—Ä–µ–¥–Ω—è—è —Å–∫–æ—Ä–æ—Å—Ç—å: {processing_stats['total_processed']/total_time:.1f} –∑–∞–ø–∏—Å–µ–π/—Å–µ–∫\")\n",
    "print(f\"   –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –Ω–∞ –∑–∞–ø–∏—Å—å: {avg_processing_time*1000:.2f} –º—Å\")\n",
    "print(f\"   –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç —Å–∂–∞—Ç–∏—è —Ç–µ–∫—Å—Ç–∞: {compression_ratio:.2f}\")\n",
    "\n",
    "# –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —É–ª—É—á—à–µ–Ω–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã –æ–±—Ä–∞–±–æ—Ç–∫–∏\n",
    "print(f\"\\nüìù –ü—Ä–∏–º–µ—Ä—ã –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å –∞–Ω–∞–ª–∏–∑–æ–º:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "sample_indices = np.random.choice(len(processed_data), min(3, len(processed_data)), replace=False)\n",
    "\n",
    "for i, idx in enumerate(sample_indices, 1):\n",
    "    original = processed_data.iloc[idx][main_name_column]\n",
    "    processed = processed_data.iloc[idx]['processed_name']\n",
    "    \n",
    "    print(f\"{i}. –ò—Å—Ö–æ–¥–Ω—ã–π ({len(original)} —Å–∏–º–≤–æ–ª–æ–≤):\")\n",
    "    print(f\"   {original}\")\n",
    "    print(f\"   –û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π ({len(processed)} —Å–∏–º–≤–æ–ª–æ–≤):\")\n",
    "    print(f\"   {processed}\")\n",
    "    \n",
    "    # –ê–Ω–∞–ª–∏–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π\n",
    "    changes = []\n",
    "    if len(processed) < len(original) * 0.8:\n",
    "        changes.append(\"–∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ–µ —Å–æ–∫—Ä–∞—â–µ–Ω–∏–µ\")\n",
    "    if original.lower() != processed:\n",
    "        changes.append(\"–Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–≥–∏—Å—Ç—Ä–∞\")\n",
    "    if re.search(r'\\d', processed) and re.search(r'\\d', original):\n",
    "        changes.append(\"—Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã —á–∏—Å–ª–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è\")\n",
    "    \n",
    "    if changes:\n",
    "        print(f\"   üìã –ò–∑–º–µ–Ω–µ–Ω–∏—è: {', '.join(changes)}\")\n",
    "    print()\n",
    "\n",
    "print(f\"\\nüéØ –î–∞–Ω–Ω—ã–µ –≥–æ—Ç–æ–≤—ã –¥–ª—è –ø–æ–∏—Å–∫–∞ –∞–Ω–∞–ª–æ–≥–æ–≤!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–æ–∏—Å–∫–æ–≤—ã—Ö –¥–≤–∏–∂–∫–æ–≤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–æ–∏—Å–∫–æ–≤—ã—Ö –¥–≤–∏–∂–∫–æ–≤...\n",
      "üìö –ö–æ—Ä–ø—É—Å –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: 5 –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–π\n",
      "üîß –û–±—É—á–µ–Ω–∏–µ –Ω–µ—á–µ—Ç–∫–æ–≥–æ –ø–æ–∏—Å–∫–æ–≤–æ–≥–æ –¥–≤–∏–∂–∫–∞...\n",
      "‚úÖ –ù–µ—á–µ—Ç–∫–∏–π –ø–æ–∏—Å–∫ –Ω–∞—Å—Ç—Ä–æ–µ–Ω\n",
      "üß† –û–±—É—á–µ–Ω–∏–µ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–∏—Å–∫–æ–≤–æ–≥–æ –¥–≤–∏–∂–∫–∞...\n",
      "‚úÖ –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ –Ω–∞—Å—Ç—Ä–æ–µ–Ω\n",
      "‚ùå –û—à–∏–±–∫–∞ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –≥–∏–±—Ä–∏–¥–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞: Task <Task pending name='Task-10' coro=<SemanticSearchEngine.fit_async() running at /Users/igor/Desktop/PythonProjects/SAMe/src/same/search_engine/semantic_search.py:101> cb=[_run_until_complete_cb() at /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py:181]> got Future <Future pending> attached to a different loop\n",
      "\n",
      "üéØ –î–æ—Å—Ç—É–ø–Ω—ã–µ –ø–æ–∏—Å–∫–æ–≤—ã–µ –¥–≤–∏–∂–∫–∏: ['fuzzy', 'semantic']\n",
      "\n",
      "üìã –í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –ø–æ–∏—Å–∫–æ–≤—ã—Ö –¥–≤–∏–∂–∫–æ–≤ SAMe:\n",
      "\n",
      "‚úÖ FuzzySearchConfig - –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã:\n",
      "   ‚Ä¢ tfidf_max_features, tfidf_ngram_range, tfidf_min_df, tfidf_max_df\n",
      "   ‚Ä¢ cosine_threshold, fuzzy_threshold, levenshtein_threshold\n",
      "   ‚Ä¢ cosine_weight, fuzzy_weight, levenshtein_weight\n",
      "   ‚Ä¢ max_candidates, top_k_results, similarity_threshold\n",
      "   ‚Ä¢ use_stemming (–¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å notebook)\n",
      "\n",
      "‚úÖ SemanticSearchConfig - –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã:\n",
      "   ‚Ä¢ model_name, embedding_dim, index_type, nlist, nprobe\n",
      "   ‚Ä¢ similarity_threshold, top_k_results, batch_size\n",
      "   ‚Ä¢ normalize_embeddings, use_gpu\n",
      "\n",
      "‚úÖ HybridSearchConfig - –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã:\n",
      "   ‚Ä¢ fuzzy_weight, semantic_weight, final_top_k\n",
      "   ‚Ä¢ min_fuzzy_score, min_semantic_score, max_candidates_per_method\n",
      "   ‚Ä¢ combination_strategy, enable_parallel_search, max_workers\n",
      "\n",
      "üí° –û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏:\n",
      "   ‚Ä¢ HybridSearchEngine —Å–æ–∑–¥–∞–µ—Ç —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–µ —ç–∫–∑–µ–º–ø–ª—è—Ä—ã –¥–≤–∏–∂–∫–æ–≤\n",
      "   ‚Ä¢ –ú–µ—Ç–æ–¥ fit() –¥–ª—è HybridSearchEngine –ø—Ä–∏–Ω–∏–º–∞–µ—Ç —Ç–æ–ª—å–∫–æ documents\n",
      "   ‚Ä¢ –í—Å–µ –¥–≤–∏–∂–∫–∏ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç –∞–ª–∏–∞—Å—ã –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏\n",
      "   ‚Ä¢ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –Ω–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤\n"
     ]
    }
   ],
   "source": [
    "# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –ø–æ–∏—Å–∫–æ–≤—ã—Ö –¥–≤–∏–∂–∫–æ–≤ –¥–ª—è –ø–æ–∏—Å–∫–∞ –∞–Ω–∞–ª–æ–≥–æ–≤\n",
    "print(\"üîç –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–æ–∏—Å–∫–æ–≤—ã—Ö –¥–≤–∏–∂–∫–æ–≤...\")\n",
    "\n",
    "# –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∫–æ—Ä–ø—É—Å–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è –ø–æ–∏—Å–∫–∞\n",
    "documents = processed_data['processed_name'].tolist()\n",
    "original_names = processed_data[main_name_column].tolist()\n",
    "document_ids = processed_data.index.tolist()\n",
    "\n",
    "print(f\"üìö –ö–æ—Ä–ø—É—Å –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {len(documents)} –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–π\")\n",
    "\n",
    "# 1. –ù–µ—á–µ—Ç–∫–∏–π –ø–æ–∏—Å–∫ (Fuzzy Search)\n",
    "try:\n",
    "    fuzzy_config = create_safe_config(\n",
    "        FuzzySearchConfig,\n",
    "        similarity_threshold=0.3,      # –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è (alias –¥–ª—è cosine_threshold)\n",
    "        top_k_results=10,             # –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è\n",
    "        tfidf_max_features=5000,      # –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è\n",
    "        tfidf_ngram_range=(1, 3),     # –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è\n",
    "        cosine_threshold=0.3,         # –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è\n",
    "        fuzzy_threshold=60,           # –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è\n",
    "        max_candidates=100,           # –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è\n",
    "        use_stemming=False            # –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è (–¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏)\n",
    "    )\n",
    "    fuzzy_engine = FuzzySearchEngine(fuzzy_config)\n",
    "    \n",
    "    print(\"üîß –û–±—É—á–µ–Ω–∏–µ –Ω–µ—á–µ—Ç–∫–æ–≥–æ –ø–æ–∏—Å–∫–æ–≤–æ–≥–æ –¥–≤–∏–∂–∫–∞...\")\n",
    "    fuzzy_engine.fit(documents)\n",
    "    print(\"‚úÖ –ù–µ—á–µ—Ç–∫–∏–π –ø–æ–∏—Å–∫ –Ω–∞—Å—Ç—Ä–æ–µ–Ω\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå –û—à–∏–±–∫–∞ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –Ω–µ—á–µ—Ç–∫–æ–≥–æ –ø–æ–∏—Å–∫–∞: {e}\")\n",
    "    fuzzy_engine = None\n",
    "\n",
    "# 2. –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ \n",
    "try:\n",
    "    semantic_config = create_safe_config(\n",
    "        SemanticSearchConfig,\n",
    "        model_name=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\",  # –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è\n",
    "        similarity_threshold=0.5,     # –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è\n",
    "        top_k_results=10,            # –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è\n",
    "        batch_size=32,               # –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è\n",
    "        normalize_embeddings=True,   # –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è\n",
    "        use_gpu=False                # –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è\n",
    "    )\n",
    "    semantic_engine = SemanticSearchEngine(semantic_config)\n",
    "    \n",
    "    print(\"üß† –û–±—É—á–µ–Ω–∏–µ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–∏—Å–∫–æ–≤–æ–≥–æ –¥–≤–∏–∂–∫–∞...\")\n",
    "    semantic_engine.fit(documents)\n",
    "    print(\"‚úÖ –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ –Ω–∞—Å—Ç—Ä–æ–µ–Ω\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå –û—à–∏–±–∫–∞ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–∏—Å–∫–∞: {e}\")\n",
    "    print(\"üí° –í–æ–∑–º–æ–∂–Ω–æ, –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ (transformers, sentence-transformers)\")\n",
    "    semantic_engine = None\n",
    "\n",
    "# 3. –ì–∏–±—Ä–∏–¥–Ω—ã–π –ø–æ–∏—Å–∫ \n",
    "if fuzzy_engine and semantic_engine:\n",
    "    try:\n",
    "        hybrid_config = create_safe_config(\n",
    "            HybridSearchConfig,\n",
    "            fuzzy_weight=0.4,           # –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è\n",
    "            semantic_weight=0.6,        # –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è\n",
    "            final_top_k=10,            # –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è\n",
    "            max_candidates_per_method=50,  # –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è\n",
    "            combination_strategy=\"weighted_sum\",  # –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è\n",
    "            enable_parallel_search=True,  # –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è\n",
    "        )\n",
    "        hybrid_engine = HybridSearchEngine(hybrid_config)\n",
    "        hybrid_engine.fit(documents)  \n",
    "        print(\"‚úÖ –ì–∏–±—Ä–∏–¥–Ω—ã–π –ø–æ–∏—Å–∫ –Ω–∞—Å—Ç—Ä–æ–µ–Ω\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå –û—à–∏–±–∫–∞ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –≥–∏–±—Ä–∏–¥–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞: {e}\")\n",
    "        hybrid_engine = None\n",
    "else:\n",
    "    hybrid_engine = None\n",
    "    print(\"‚ö†Ô∏è –ì–∏–±—Ä–∏–¥–Ω—ã–π –ø–æ–∏—Å–∫ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω (—Ç—Ä–µ–±—É—é—Ç—Å—è –æ–±–∞ –¥–≤–∏–∂–∫–∞)\")\n",
    "\n",
    "# –°–æ–∑–¥–∞–µ–º —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –¥–≤–∏–∂–∫–æ–≤\n",
    "available_engines = {}\n",
    "if fuzzy_engine:\n",
    "    available_engines['fuzzy'] = fuzzy_engine\n",
    "if semantic_engine:\n",
    "    available_engines['semantic'] = semantic_engine\n",
    "if hybrid_engine:\n",
    "    available_engines['hybrid'] = hybrid_engine\n",
    "\n",
    "print(f\"\\nüéØ –î–æ—Å—Ç—É–ø–Ω—ã–µ –ø–æ–∏—Å–∫–æ–≤—ã–µ –¥–≤–∏–∂–∫–∏: {list(available_engines.keys())}\")\n",
    "\n",
    "# –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π –∏ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π –ø–æ–∏—Å–∫–æ–≤—ã—Ö –¥–≤–∏–∂–∫–æ–≤\n",
    "print(f\"\\nüìã –í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –ø–æ–∏—Å–∫–æ–≤—ã—Ö –¥–≤–∏–∂–∫–æ–≤ SAMe:\")\n",
    "print(f\"\\n‚úÖ FuzzySearchConfig - –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã:\")\n",
    "print(f\"   ‚Ä¢ tfidf_max_features, tfidf_ngram_range, tfidf_min_df, tfidf_max_df\")\n",
    "print(f\"   ‚Ä¢ cosine_threshold, fuzzy_threshold, levenshtein_threshold\")\n",
    "print(f\"   ‚Ä¢ cosine_weight, fuzzy_weight, levenshtein_weight\")\n",
    "print(f\"   ‚Ä¢ max_candidates, top_k_results, similarity_threshold\")\n",
    "print(f\"   ‚Ä¢ use_stemming (–¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å notebook)\")\n",
    "\n",
    "print(f\"\\n‚úÖ SemanticSearchConfig - –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã:\")\n",
    "print(f\"   ‚Ä¢ model_name, embedding_dim, index_type, nlist, nprobe\")\n",
    "print(f\"   ‚Ä¢ similarity_threshold, top_k_results, batch_size\")\n",
    "print(f\"   ‚Ä¢ normalize_embeddings, use_gpu\")\n",
    "\n",
    "print(f\"\\n‚úÖ HybridSearchConfig - –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã:\")\n",
    "print(f\"   ‚Ä¢ fuzzy_weight, semantic_weight, final_top_k\")\n",
    "print(f\"   ‚Ä¢ min_fuzzy_score, min_semantic_score, max_candidates_per_method\")\n",
    "print(f\"   ‚Ä¢ combination_strategy, enable_parallel_search, max_workers\")\n",
    "\n",
    "print(f\"\\nüí° –û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏:\")\n",
    "print(f\"   ‚Ä¢ HybridSearchEngine —Å–æ–∑–¥–∞–µ—Ç —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–µ —ç–∫–∑–µ–º–ø–ª—è—Ä—ã –¥–≤–∏–∂–∫–æ–≤\")\n",
    "print(f\"   ‚Ä¢ –ú–µ—Ç–æ–¥ fit() –¥–ª—è HybridSearchEngine –ø—Ä–∏–Ω–∏–º–∞–µ—Ç —Ç–æ–ª—å–∫–æ documents\")\n",
    "print(f\"   ‚Ä¢ –í—Å–µ –¥–≤–∏–∂–∫–∏ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç –∞–ª–∏–∞—Å—ã –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏\")\n",
    "print(f\"   ‚Ä¢ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –Ω–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. –§—É–Ω–∫—Ü–∏–∏ –¥–ª—è –ø–æ–∏—Å–∫–∞ –∞–Ω–∞–ª–æ–≥–æ–≤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ –§—É–Ω–∫—Ü–∏–∏ –ø–æ–∏—Å–∫–∞ –∞–Ω–∞–ª–æ–≥–æ–≤ –≥–æ—Ç–æ–≤—ã\n"
     ]
    }
   ],
   "source": [
    "# –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è –ø–æ–∏—Å–∫–∞ –∞–Ω–∞–ª–æ–≥–æ–≤\n",
    "\n",
    "def search_analogs(query: str, engine_type: str = 'fuzzy', top_k: int = 5) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    –ü–æ–∏—Å–∫ –∞–Ω–∞–ª–æ–≥–æ–≤ –¥–ª—è –∑–∞–¥–∞–Ω–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞\n",
    "    \n",
    "    Args:\n",
    "        query: –ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å (–Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞)\n",
    "        engine_type: –¢–∏–ø –ø–æ–∏—Å–∫–æ–≤–æ–≥–æ –¥–≤–∏–∂–∫–∞ ('fuzzy', 'semantic', 'hybrid')\n",
    "        top_k: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\n",
    "    \n",
    "    Returns:\n",
    "        –°–ø–∏—Å–æ–∫ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –∞–Ω–∞–ª–æ–≥–æ–≤ —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏\n",
    "    \"\"\"\n",
    "    if engine_type not in available_engines:\n",
    "        print(f\"‚ùå –î–≤–∏–∂–æ–∫ '{engine_type}' –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω\")\n",
    "        return []\n",
    "    \n",
    "    engine = available_engines[engine_type]\n",
    "    \n",
    "    try:\n",
    "        if 'final_preprocess_function' in globals():\n",
    "            processed_query = final_preprocess_function(query)\n",
    "        else:\n",
    "            processed_query = str(query).lower().strip()\n",
    "    except Exception:\n",
    "        processed_query = str(query).lower().strip()\n",
    "    \n",
    "    # –ü–æ–∏—Å–∫\n",
    "    try:\n",
    "        results = engine.search(processed_query, top_k=top_k)\n",
    "        \n",
    "        # –û–±–æ–≥–∞—â–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏\n",
    "        enriched_results = []\n",
    "        for result in results:\n",
    "            # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï 2: –ü—Ä–∞–≤–∏–ª—å–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ document_id\n",
    "            doc_idx = result.get('document_id', result.get('index', result.get('doc_id')))\n",
    "            \n",
    "            if doc_idx is not None and doc_idx < len(processed_data):\n",
    "                row = processed_data.iloc[doc_idx]\n",
    "                \n",
    "                # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï 3: –ü—Ä–∞–≤–∏–ª—å–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ score\n",
    "                score = 0.0\n",
    "                for score_field in ['score', 'similarity_score', 'combined_score', 'hybrid_score', 'cosine_score', 'fuzzy_score']:\n",
    "                    if score_field in result:\n",
    "                        score = result[score_field]\n",
    "                        break\n",
    "                \n",
    "                enriched_result = {\n",
    "                    'score': float(score),\n",
    "                    'original_name': row[main_name_column],\n",
    "                    'processed_name': result.get('document', ''),\n",
    "                    'code': row.get('–ö–æ–¥', ''),\n",
    "                    'group': row.get('–ì—Ä—É–ø–ø–∞', ''),\n",
    "                    'type': row.get('–í–∏–¥–ù–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä—ã', ''),\n",
    "                    'index': doc_idx\n",
    "                }\n",
    "                enriched_results.append(enriched_result)\n",
    "        \n",
    "        return enriched_results\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞: {e}\")\n",
    "        return []\n",
    "\n",
    "\n",
    "def display_search_results(query: str, results: List[Dict], engine_type: str):\n",
    "    \"\"\"\n",
    "    –ö—Ä–∞—Å–∏–≤–æ–µ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ–∏—Å–∫–∞\n",
    "    \"\"\"\n",
    "    print(f\"\\nüîç –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞ ({engine_type.upper()})\")\n",
    "    print(f\"üìù –ó–∞–ø—Ä–æ—Å: '{query}'\")\n",
    "    print(f\"üìä –ù–∞–π–¥–µ–Ω–æ: {len(results)} –∞–Ω–∞–ª–æ–≥–æ–≤\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    for i, result in enumerate(results, 1):\n",
    "        print(f\"{i}. üì¶ {result['original_name']}\")\n",
    "        print(f\"   üè∑Ô∏è  –ö–æ–¥: {result['code']}\")\n",
    "        print(f\"   üìÇ –ì—Ä—É–ø–ø–∞: {result['group']}\")\n",
    "        print(f\"   üéØ –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: {result['score']:.3f}\")\n",
    "        print()\n",
    "\n",
    "def compare_engines(query: str, top_k: int = 5):\n",
    "    \"\"\"\n",
    "    –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Ä–∞–∑–Ω—ã—Ö –ø–æ–∏—Å–∫–æ–≤—ã—Ö –¥–≤–∏–∂–∫–æ–≤\n",
    "    \"\"\"\n",
    "    print(f\"\\nüÜö –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø–æ–∏—Å–∫–æ–≤—ã—Ö –¥–≤–∏–∂–∫–æ–≤\")\n",
    "    print(f\"üìù –ó–∞–ø—Ä–æ—Å: '{query}'\")\n",
    "    print(\"=\" * 100)\n",
    "    \n",
    "    all_results = {}\n",
    "    \n",
    "    for engine_name in available_engines.keys():\n",
    "        results = search_analogs(query, engine_name, top_k)\n",
    "        all_results[engine_name] = results\n",
    "        \n",
    "        print(f\"\\nüîß {engine_name.upper()} ENGINE:\")\n",
    "        for i, result in enumerate(results[:3], 1):  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ø-3\n",
    "            print(f\"  {i}. {result['original_name'][:60]}... (—Å–∫–æ—Ä: {result['score']:.3f})\")\n",
    "    \n",
    "    return all_results\n",
    "\n",
    "print(\"‚úÖ –§—É–Ω–∫—Ü–∏–∏ –ø–æ–∏—Å–∫–∞ –∞–Ω–∞–ª–æ–≥–æ–≤ –≥–æ—Ç–æ–≤—ã\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–º–µ—Ä—ã –ø–æ–∏—Å–∫–∞ –∞–Ω–∞–ª–æ–≥–æ–≤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ –ü—Ä–∏–º–µ—Ä—ã –ø–æ–∏—Å–∫–æ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤:\n",
      "1. C–≤–µ—Ç–∏–ª—å–Ω–∏–∫ LED –ø–∞–Ω–µ–ª—å 50W\n",
      "2. K–æ–ª—å—Ü–æ –∫—Ä–µ–ø–ª–µ–Ω–∏—è –≥—Ä—É–∑–∞ –¥–æ 3\n",
      "3. –ê–≤—Ç–æ–ª–∞–º–ø–æ—á–∫–∞ –ù7 24-70W\n",
      "4. –ê–≤—Ç–æ—ç–º–∞–ª—å Reoflex\n",
      "5. –ê–¥–∞–ø—Ç–µ—Ä –ø–∏—Ç–∞–Ω–∏—è\n"
     ]
    }
   ],
   "source": [
    "# –ü—Ä–∏–º–µ—Ä—ã –ø–æ–∏—Å–∫–æ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏\n",
    "example_queries = [\n",
    "    \"C–≤–µ—Ç–∏–ª—å–Ω–∏–∫ LED –ø–∞–Ω–µ–ª—å 50W\",\n",
    "    \"K–æ–ª—å—Ü–æ –∫—Ä–µ–ø–ª–µ–Ω–∏—è –≥—Ä—É–∑–∞ –¥–æ 3\",\n",
    "    \"–ê–≤—Ç–æ–ª–∞–º–ø–æ—á–∫–∞ –ù7 24-70W\",\n",
    "    \"–ê–≤—Ç–æ—ç–º–∞–ª—å Reoflex\",\n",
    "    \"–ê–¥–∞–ø—Ç–µ—Ä –ø–∏—Ç–∞–Ω–∏—è\"\n",
    "]\n",
    "\n",
    "if len(processed_data) > 0:\n",
    "    # –ë–µ—Ä–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–ª—É—á–∞–π–Ω—ã—Ö –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–π –∏–∑ –¥–∞—Ç–∞—Å–µ—Ç–∞\n",
    "    sample_products = processed_data[main_name_column].sample(min(3, len(processed_data))).tolist()\n",
    "    example_queries.extend(sample_products)\n",
    "\n",
    "print(\"üéØ –ü—Ä–∏–º–µ—Ä—ã –ø–æ–∏—Å–∫–æ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤:\")\n",
    "for i, query in enumerate(example_queries[:5], 1):\n",
    "    print(f\"{i}. {query}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –ø–æ–∏—Å–∫–∞ –∞–Ω–∞–ª–æ–≥–æ–≤\n",
      "==================================================\n",
      "\n",
      "============================================================\n",
      "\n",
      "üîç –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞ (FUZZY)\n",
      "üìù –ó–∞–ø—Ä–æ—Å: 'C–≤–µ—Ç–∏–ª—å–Ω–∏–∫ LED –ø–∞–Ω–µ–ª—å 50W'\n",
      "üìä –ù–∞–π–¥–µ–Ω–æ: 0 –∞–Ω–∞–ª–æ–≥–æ–≤\n",
      "================================================================================\n",
      "\n",
      "============================================================\n",
      "\n",
      "üîç –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞ (FUZZY)\n",
      "üìù –ó–∞–ø—Ä–æ—Å: 'K–æ–ª—å—Ü–æ –∫—Ä–µ–ø–ª–µ–Ω–∏—è –≥—Ä—É–∑–∞ –¥–æ 3'\n",
      "üìä –ù–∞–π–¥–µ–Ω–æ: 0 –∞–Ω–∞–ª–æ–≥–æ–≤\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –ø–æ–∏—Å–∫–∞ –∞–Ω–∞–ª–æ–≥–æ–≤\n",
    "print(\"üöÄ –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –ø–æ–∏—Å–∫–∞ –∞–Ω–∞–ª–æ–≥–æ–≤\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# –í—ã–±–∏—Ä–∞–µ–º –ø–µ—Ä–≤—ã–π –¥–æ—Å—Ç—É–ø–Ω—ã–π –¥–≤–∏–∂–æ–∫ –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏\n",
    "demo_engine = list(available_engines.keys())[0] if available_engines else None\n",
    "\n",
    "if demo_engine:\n",
    "    # –î–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ–º –ø–æ–∏—Å–∫ –¥–ª—è –ø–µ—Ä–≤—ã—Ö 2-3 –∑–∞–ø—Ä–æ—Å–æ–≤\n",
    "    for query in example_queries[:2]:\n",
    "        print(f\"\\n\" + \"=\"*60)\n",
    "        results = search_analogs(query, demo_engine, top_k=5)\n",
    "        display_search_results(query, results, demo_engine)\n",
    "        \n",
    "        # –ï—Å–ª–∏ –µ—Å—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã, –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é\n",
    "        if results:\n",
    "            print(f\"üí° –ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤:\")\n",
    "            scores = [r['score'] for r in results]\n",
    "            print(f\"   –°—Ä–µ–¥–Ω–∏–π —Å–∫–æ—Ä —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏: {np.mean(scores):.3f}\")\n",
    "            print(f\"   –†–∞–∑–±—Ä–æ—Å —Å–∫–æ—Ä–æ–≤: {np.std(scores):.3f}\")\n",
    "            \n",
    "            # –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º\n",
    "            groups = [r['group'] for r in results if r['group']]\n",
    "            if groups:\n",
    "                group_counts = Counter(groups)\n",
    "                print(f\"   –ì—Ä—É–ø–ø—ã —Ç–æ–≤–∞—Ä–æ–≤: {dict(group_counts)}\")\n",
    "else:\n",
    "    print(\"‚ùå –ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –ø–æ–∏—Å–∫–æ–≤—ã—Ö –¥–≤–∏–∂–∫–æ–≤ –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üÜö –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø–æ–∏—Å–∫–æ–≤—ã—Ö –¥–≤–∏–∂–∫–æ–≤\n",
      "============================================================\n",
      "\n",
      "üÜö –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø–æ–∏—Å–∫–æ–≤—ã—Ö –¥–≤–∏–∂–∫–æ–≤\n",
      "üìù –ó–∞–ø—Ä–æ—Å: 'C–≤–µ—Ç–∏–ª—å–Ω–∏–∫ LED –ø–∞–Ω–µ–ª—å 50W'\n",
      "====================================================================================================\n",
      "\n",
      "üîß FUZZY ENGINE:\n",
      "‚ùå –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞: Search engine is not fitted. Call fit() first.\n",
      "\n",
      "üîß SEMANTIC ENGINE:\n",
      "\n",
      "üìä –ê–Ω–∞–ª–∏–∑ –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–π:\n",
      "   fuzzy: 0 —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\n",
      "   semantic: 0 —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\n",
      "   –ü–µ—Ä–µ—Å–µ—á–µ–Ω–∏–µ: 0 —Ç–æ–≤–∞—Ä–æ–≤\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mZeroDivisionError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 26\u001b[39m\n\u001b[32m     24\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m   \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mengine2\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(results2)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     25\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m   –ü–µ—Ä–µ—Å–µ—á–µ–Ω–∏–µ: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(intersection)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m —Ç–æ–≤–∞—Ä–æ–≤\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m   –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –ñ–∞–∫–∫–∞—Ä–∞: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mintersection\u001b[49m\u001b[43m)\u001b[49m\u001b[43m/\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43munion\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     29\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m‚ö†Ô∏è –î–æ—Å—Ç—É–ø–µ–Ω —Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω –ø–æ–∏—Å–∫–æ–≤—ã–π –¥–≤–∏–∂–æ–∫ - —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –Ω–µ–≤–æ–∑–º–æ–∂–Ω–æ\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mZeroDivisionError\u001b[39m: division by zero"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83df48e79ecd4af3ab0daf8b6113af7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/528 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f30fea662bf64afcbfef772809d89184",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c462e4d8ec5492485dcfa27cdf55f17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f57366a56314cb2bc16cda1c189c9aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88110c074cba42fea83a14652daf6560",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7c54b5049d64d3096bc14971e5202a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/114 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78388862c72042e9a4b9001ae9b054c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "2_Dense/rust_model.ot:   0%|          | 0.00/1.58M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3135d93256b44caaa6334a2137b4a25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "2_Dense/pytorch_model.bin:   0%|          | 0.00/1.58M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0af38d10688444d985826834a8a330a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "2_Dense/model.safetensors:   0%|          | 0.00/1.58M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d7ecbbf7c5f4bc5a3f939fac0021389",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ä–∞–∑–Ω—ã—Ö –ø–æ–∏—Å–∫–æ–≤—ã—Ö –¥–≤–∏–∂–∫–æ–≤ (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–æ –Ω–µ—Å–∫–æ–ª—å–∫–æ)\n",
    "if len(available_engines) > 1:\n",
    "    print(\"\\nüÜö –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø–æ–∏—Å–∫–æ–≤—ã—Ö –¥–≤–∏–∂–∫–æ–≤\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # –í—ã–±–∏—Ä–∞–µ–º –∑–∞–ø—Ä–æ—Å –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è\n",
    "    comparison_query = example_queries[0]\n",
    "    \n",
    "    comparison_results = compare_engines(comparison_query, top_k=5)\n",
    "    \n",
    "    # –ê–Ω–∞–ª–∏–∑ –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\n",
    "    if len(comparison_results) >= 2:\n",
    "        engine_names = list(comparison_results.keys())\n",
    "        engine1, engine2 = engine_names[0], engine_names[1]\n",
    "        \n",
    "        results1 = set(r['index'] for r in comparison_results[engine1])\n",
    "        results2 = set(r['index'] for r in comparison_results[engine2])\n",
    "        \n",
    "        intersection = results1.intersection(results2)\n",
    "        union = results1.union(results2)\n",
    "        \n",
    "        print(f\"\\nüìä –ê–Ω–∞–ª–∏–∑ –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–π:\")\n",
    "        print(f\"   {engine1}: {len(results1)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\")\n",
    "        print(f\"   {engine2}: {len(results2)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\")\n",
    "        print(f\"   –ü–µ—Ä–µ—Å–µ—á–µ–Ω–∏–µ: {len(intersection)} —Ç–æ–≤–∞—Ä–æ–≤\")\n",
    "        print(f\"   –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –ñ–∞–∫–∫–∞—Ä–∞: {len(intersection)/len(union):.3f}\")\n",
    "        \n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è –î–æ—Å—Ç—É–ø–µ–Ω —Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω –ø–æ–∏—Å–∫–æ–≤—ã–π –¥–≤–∏–∂–æ–∫ - —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –Ω–µ–≤–æ–∑–º–æ–∂–Ω–æ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏ –∞–Ω–∞–ª–∏–∑ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å–∏—Å—Ç–µ–º—ã –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤...\n",
      "‚úÖ –≠–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –Ω–∞—Å—Ç—Ä–æ–µ–Ω\n",
      "\n",
      "üìä –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤:\n",
      "\n",
      "1. –ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ: C–≤–µ—Ç–∏–ª—å–Ω–∏–∫ LED –ø–∞–Ω–µ–ª—å 50W 6500k IP40 1200–º–º –î–ü–û-108 –ü—Ä–∏–∑–º–∞ Neox\n",
      "   –ù–∞–π–¥–µ–Ω–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: 3\n",
      "   - width: 6500.0 –º–º (—Ç–∏–ø: ParameterType.DIMENSION)\n",
      "   - power: 6500.0 –í—Ç (—Ç–∏–ø: ParameterType.ELECTRICAL)\n",
      "   - pressure: 40.0 –ú–ü–∞ (—Ç–∏–ø: ParameterType.PRESSURE)\n",
      "\n",
      "2. –ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ: C–≤–µ—Ç–∏–ª—å–Ω–∏–∫ –ø–æ—Ç–æ–ª–æ—á–Ω—ã–π,Osairous,–ë–µ–ª—ã–π, 30–í—Ç LED, 6500K –°–≤–µ—Ç–æ–¥–∏–æ–¥–Ω–∞—è –ø–æ—Ç–æ–ª–æ—á–Ω–∞—è\n",
      "   –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã\n",
      "\n",
      "3. –ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ: C–∏—Å—Ç–µ–º–∞ IP-DECT Yealink W80DM –∫–æ–Ω—Ç—Ä–æ–ª–ª–µ—Ä –º–∏–∫—Ä–æ—Å–æ—Ç–∞ DECT\n",
      "   –ù–∞–π–¥–µ–Ω–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: 3\n",
      "   - width: 80.0 –º–º (—Ç–∏–ø: ParameterType.DIMENSION)\n",
      "   - power: 80.0 –í—Ç (—Ç–∏–ø: ParameterType.ELECTRICAL)\n",
      "   - steel_grade: –µ–º–∞ (—Ç–∏–ø: ParameterType.MATERIAL)\n",
      "\n",
      "4. –ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ: C–ø—Ä–µ–π –¥–ª—è –≤–∞–Ω–Ω–æ–π –∫–æ–º–Ω–∞—Ç—ã Sanfor (–°–∞–Ω—Ñ–æ—Ä) 500–º–ª\n",
      "   –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã\n",
      "\n",
      "5. –ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ: C–ø—Ä–µ–π —É–ª—å—Ç—Ä–∞–±–µ–ª—ã–π Sanfor (–°–∞–Ω—Ñ–æ—Ä) 500–º–ª\n",
      "   –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã\n"
     ]
    }
   ],
   "source": [
    "# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å–∏—Å—Ç–µ–º—ã –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤\n",
    "print(\"üîß –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å–∏—Å—Ç–µ–º—ã –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤...\")\n",
    "\n",
    "try:\n",
    "    parameter_extractor = RegexParameterExtractor()\n",
    "    print(\"‚úÖ –≠–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –Ω–∞—Å—Ç—Ä–æ–µ–Ω\")\n",
    "    \n",
    "    # –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤\n",
    "    print(\"\\nüìä –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤:\")\n",
    "    \n",
    "    # –ë–µ—Ä–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ –ø—Ä–∏–º–µ—Ä–æ–≤ –∏–∑ –¥–∞–Ω–Ω—ã—Ö\n",
    "    sample_names = processed_data[main_name_column].head(5).tolist()\n",
    "    \n",
    "    for i, name in enumerate(sample_names, 1):\n",
    "        print(f\"\\n{i}. –ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ: {name}\")\n",
    "        \n",
    "        try:\n",
    "            parameters = parameter_extractor.extract_parameters(name)\n",
    "            \n",
    "            if parameters:\n",
    "                print(f\"   –ù–∞–π–¥–µ–Ω–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: {len(parameters)}\")\n",
    "                for param in parameters[:3]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 3 –ø–∞—Ä–∞–º–µ—Ç—Ä–∞\n",
    "                    unit_str = f\" {param.unit}\" if param.unit else \"\"\n",
    "                    print(f\"   - {param.name}: {param.value}{unit_str} (—Ç–∏–ø: {param.parameter_type})\")\n",
    "            else:\n",
    "                print(\"   –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è: {e}\")\n",
    "            \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå –û—à–∏–±–∫–∞ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: {e}\")\n",
    "    parameter_extractor = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéØ –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –ø–æ–∏—Å–∫–∞ –∞–Ω–∞–ª–æ–≥–æ–≤ —Å –∞–Ω–∞–ª–∏–∑–æ–º –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤\n",
      "============================================================\n",
      "\n",
      "üîç –ó–∞–ø—Ä–æ—Å: '–ë–æ–ª—Ç –ú10√ó50 –ì–û–°–¢ 7798-70'\n",
      "üìä –ù–∞–π–¥–µ–Ω–æ: 5 –∞–Ω–∞–ª–æ–≥–æ–≤\n",
      "\n",
      "–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å –∞–Ω–∞–ª–∏–∑–æ–º –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤:\n",
      "\n",
      "1. üì¶ –ë–æ–ª—Ç –ú10*40 –ì–û–°–¢ 7798-70\n",
      "   üéØ –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: 0.910\n",
      "   üîß –ü–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: 2\n",
      "   ‚öñÔ∏è  –°–æ–≤–ø–∞–¥–µ–Ω–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: 1.000\n",
      "   üìã –ü–∞—Ä–∞–º–µ—Ç—Ä—ã:\n",
      "      - gost: –ì–û–°–¢ 7798-70\n",
      "      - steel_grade: 7798-70\n",
      "\n",
      "2. üì¶ –ë–æ–ª—Ç –ú8*100 –ì–û–°–¢ 7798-70\n",
      "   üéØ –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: 0.910\n",
      "   üîß –ü–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: 2\n",
      "   ‚öñÔ∏è  –°–æ–≤–ø–∞–¥–µ–Ω–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: 1.000\n",
      "   üìã –ü–∞—Ä–∞–º–µ—Ç—Ä—ã:\n",
      "      - gost: –ì–û–°–¢ 7798-70\n",
      "      - steel_grade: 7798-70\n",
      "\n",
      "3. üì¶ –ë–æ–ª—Ç –ú10√ó14 –ì–û–°–¢ 7798 - 70\n",
      "   üéØ –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: 0.901\n",
      "   üîß –ü–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: 2\n",
      "   ‚öñÔ∏è  –°–æ–≤–ø–∞–¥–µ–Ω–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: 0.000\n",
      "   üìã –ü–∞—Ä–∞–º–µ—Ç—Ä—ã:\n",
      "      - gost: –ì–û–°–¢ 7798\n",
      "      - steel_grade: 7798\n",
      "\n",
      "4. üì¶ –ë–æ–ª—Ç –ú22—Ö100 –ì–û–°–¢ 7798-70\n",
      "   üéØ –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: 0.887\n",
      "   üîß –ü–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: 2\n",
      "   ‚öñÔ∏è  –°–æ–≤–ø–∞–¥–µ–Ω–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: 1.000\n",
      "   üìã –ü–∞—Ä–∞–º–µ—Ç—Ä—ã:\n",
      "      - gost: –ì–û–°–¢ 7798-70\n",
      "      - steel_grade: 7798-70\n",
      "\n",
      "5. üì¶ –ë–æ–ª—Ç –ú30–•100 –ì–û–°–¢ 7798-70\n",
      "   üéØ –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: 0.887\n",
      "   üîß –ü–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: 2\n",
      "   ‚öñÔ∏è  –°–æ–≤–ø–∞–¥–µ–Ω–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: 1.000\n",
      "   üìã –ü–∞—Ä–∞–º–µ—Ç—Ä—ã:\n",
      "      - gost: –ì–û–°–¢ 7798-70\n",
      "      - steel_grade: 7798-70\n",
      "\n",
      "‚úÖ –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞\n"
     ]
    }
   ],
   "source": [
    "# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–æ–∏—Å–∫–∞ –∞–Ω–∞–ª–æ–≥–æ–≤ —Å —É—á–µ—Ç–æ–º –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤\n",
    "def search_analogs_with_parameters(query: str, engine_type: str = 'fuzzy', top_k: int = 5):\n",
    "    \"\"\"\n",
    "    –ü–æ–∏—Å–∫ –∞–Ω–∞–ª–æ–≥–æ–≤ —Å –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ–º –∏ –∞–Ω–∞–ª–∏–∑–æ–º –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤\n",
    "    \"\"\"\n",
    "    # –û–±—ã—á–Ω—ã–π –ø–æ–∏—Å–∫\n",
    "    results = search_analogs(query, engine_type, top_k)\n",
    "    \n",
    "    if not parameter_extractor or not results:\n",
    "        return results\n",
    "    \n",
    "    # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏–∑ –∑–∞–ø—Ä–æ—Å–∞\n",
    "    try:\n",
    "        query_params = parameter_extractor.extract_parameters(query)\n",
    "        query_param_dict = {p.name: p.value for p in query_params}\n",
    "    except:\n",
    "        query_param_dict = {}\n",
    "    \n",
    "    # –û–±–æ–≥–∞—â–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏\n",
    "    enriched_results = []\n",
    "    \n",
    "    for result in results:\n",
    "        try:\n",
    "            # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏–∑ –Ω–∞–π–¥–µ–Ω–Ω–æ–≥–æ —Ç–æ–≤–∞—Ä–∞\n",
    "            item_params = parameter_extractor.extract_parameters(result['original_name'])\n",
    "            item_param_dict = {p.name: p.value for p in item_params}\n",
    "            \n",
    "            # –í—ã—á–∏—Å–ª—è–µ–º —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤\n",
    "            param_match_score = 0\n",
    "            if query_param_dict and item_param_dict:\n",
    "                common_params = set(query_param_dict.keys()).intersection(set(item_param_dict.keys()))\n",
    "                if common_params:\n",
    "                    matches = sum(1 for param in common_params \n",
    "                                if str(query_param_dict[param]).lower() == str(item_param_dict[param]).lower())\n",
    "                    param_match_score = matches / len(common_params)\n",
    "            \n",
    "            # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞—Ö –∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—É\n",
    "            result['parameters'] = item_params\n",
    "            result['parameter_match_score'] = param_match_score\n",
    "            result['parameter_count'] = len(item_params)\n",
    "            \n",
    "            enriched_results.append(result)\n",
    "            \n",
    "        except Exception as e:\n",
    "            # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã, –¥–æ–±–∞–≤–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –±–µ–∑ –Ω–∏—Ö\n",
    "            result['parameters'] = []\n",
    "            result['parameter_match_score'] = 0\n",
    "            result['parameter_count'] = 0\n",
    "            enriched_results.append(result)\n",
    "    \n",
    "    return enriched_results\n",
    "\n",
    "# –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –ø–æ–∏—Å–∫–∞ —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏\n",
    "if parameter_extractor and available_engines:\n",
    "    print(\"\\nüéØ –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –ø–æ–∏—Å–∫–∞ –∞–Ω–∞–ª–æ–≥–æ–≤ —Å –∞–Ω–∞–ª–∏–∑–æ–º –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    demo_query = \"–ë–æ–ª—Ç –ú10√ó50 –ì–û–°–¢ 7798-70\"\n",
    "    engine_name = list(available_engines.keys())[0]\n",
    "    \n",
    "    param_results = search_analogs_with_parameters(demo_query, engine_name, top_k=5)\n",
    "    \n",
    "    print(f\"\\nüîç –ó–∞–ø—Ä–æ—Å: '{demo_query}'\")\n",
    "    print(f\"üìä –ù–∞–π–¥–µ–Ω–æ: {len(param_results)} –∞–Ω–∞–ª–æ–≥–æ–≤\")\n",
    "    print(\"\\n–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å –∞–Ω–∞–ª–∏–∑–æ–º –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤:\")\n",
    "    \n",
    "    for i, result in enumerate(param_results, 1):\n",
    "        print(f\"\\n{i}. üì¶ {result['original_name']}\")\n",
    "        print(f\"   üéØ –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: {result['score']:.3f}\")\n",
    "        print(f\"   üîß –ü–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: {result['parameter_count']}\")\n",
    "        print(f\"   ‚öñÔ∏è  –°–æ–≤–ø–∞–¥–µ–Ω–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: {result['parameter_match_score']:.3f}\")\n",
    "        \n",
    "        if result['parameters']:\n",
    "            print(f\"   üìã –ü–∞—Ä–∞–º–µ—Ç—Ä—ã:\")\n",
    "            for param in result['parameters'][:3]:\n",
    "                unit_str = f\" {param.unit}\" if param.unit else \"\"\n",
    "                print(f\"      - {param.name}: {param.value}{unit_str}\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è –ü–æ–∏—Å–∫ —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω\")\n",
    "\n",
    "print(\"\\n‚úÖ –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ —Å–∏—Å—Ç–µ–º—ã –ø–æ–∏—Å–∫–∞ –∞–Ω–∞–ª–æ–≥–æ–≤\n",
      "============================================================\n",
      "\n",
      "üîß –ê–Ω–∞–ª–∏–∑ –¥–≤–∏–∂–∫–∞: FUZZY\n",
      "   ‚è±Ô∏è  –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –ø–æ–∏—Å–∫–∞: 0.015 —Å–µ–∫\n",
      "   üìä –°—Ä–µ–¥–Ω–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: 6.3\n",
      "   üéØ –°—Ä–µ–¥–Ω–∏–π —Å–∫–æ—Ä —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏: 0.627\n",
      "\n",
      "üîß –ê–Ω–∞–ª–∏–∑ –¥–≤–∏–∂–∫–∞: SEMANTIC\n",
      "‚ùå –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞: Search engine is not fitted. Call fit() first.\n",
      "‚ùå –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞: Search engine is not fitted. Call fit() first.\n",
      "‚ùå –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞: Search engine is not fitted. Call fit() first.\n",
      "   ‚è±Ô∏è  –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –ø–æ–∏—Å–∫–∞: 0.000 —Å–µ–∫\n",
      "   üìä –°—Ä–µ–¥–Ω–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: 0.0\n",
      "   üéØ –°—Ä–µ–¥–Ω–∏–π —Å–∫–æ—Ä —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏: 0.000\n",
      "\n",
      "üîß –ê–Ω–∞–ª–∏–∑ –¥–≤–∏–∂–∫–∞: HYBRID\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f80d7ead085e4a2cb8eaab19e42db481",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e19d2c828da4d2f8d91bb99ffccd0a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚è±Ô∏è  –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –ø–æ–∏—Å–∫–∞: 0.031 —Å–µ–∫\n",
      "   üìä –°—Ä–µ–¥–Ω–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: 10.0\n",
      "   üéØ –°—Ä–µ–¥–Ω–∏–π —Å–∫–æ—Ä —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏: 0.802\n",
      "\n",
      "üìã –°—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏:\n",
      "–î–≤–∏–∂–æ–∫       –í—Ä–µ–º—è (—Å–µ–∫)  –†–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤  –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å  \n",
      "-------------------------------------------------------\n",
      "fuzzy        0.015        6.3          0.627          \n",
      "semantic     0.000        0.0          0.000          \n",
      "hybrid       0.031        10.0         0.802          \n"
     ]
    }
   ],
   "source": [
    "# –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ–∏—Å–∫–∞\n",
    "print(\"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ —Å–∏—Å—Ç–µ–º—ã –ø–æ–∏—Å–∫–∞ –∞–Ω–∞–ª–æ–≥–æ–≤\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if available_engines:\n",
    "    # –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏\n",
    "    performance_stats = {}\n",
    "    \n",
    "    for engine_name, engine in available_engines.items():\n",
    "        print(f\"\\nüîß –ê–Ω–∞–ª–∏–∑ –¥–≤–∏–∂–∫–∞: {engine_name.upper()}\")\n",
    "        \n",
    "        # –¢–µ—Å—Ç–∏—Ä—É–µ–º –Ω–∞ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –∑–∞–ø—Ä–æ—Å–∞—Ö\n",
    "        test_queries = example_queries[:3]\n",
    "        search_times = []\n",
    "        result_counts = []\n",
    "        avg_scores = []\n",
    "        \n",
    "        for query in test_queries:\n",
    "            start_time = time.time()\n",
    "            results = search_analogs(query, engine_name, top_k=10)\n",
    "            search_time = time.time() - start_time\n",
    "            \n",
    "            search_times.append(search_time)\n",
    "            result_counts.append(len(results))\n",
    "            \n",
    "            if results:\n",
    "                avg_scores.append(np.mean([r['score'] for r in results]))\n",
    "            else:\n",
    "                avg_scores.append(0)\n",
    "        \n",
    "        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É\n",
    "        performance_stats[engine_name] = {\n",
    "            'avg_search_time': np.mean(search_times),\n",
    "            'avg_results_count': np.mean(result_counts),\n",
    "            'avg_relevance_score': np.mean(avg_scores)\n",
    "        }\n",
    "        \n",
    "        print(f\"   ‚è±Ô∏è  –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –ø–æ–∏—Å–∫–∞: {np.mean(search_times):.3f} —Å–µ–∫\")\n",
    "        print(f\"   üìä –°—Ä–µ–¥–Ω–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {np.mean(result_counts):.1f}\")\n",
    "        print(f\"   üéØ –°—Ä–µ–¥–Ω–∏–π —Å–∫–æ—Ä —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏: {np.mean(avg_scores):.3f}\")\n",
    "    \n",
    "    # –°—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞\n",
    "    if len(performance_stats) > 1:\n",
    "        print(f\"\\nüìã –°—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏:\")\n",
    "        print(f\"{'–î–≤–∏–∂–æ–∫':<12} {'–í—Ä–µ–º—è (—Å–µ–∫)':<12} {'–†–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤':<12} {'–†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å':<15}\")\n",
    "        print(\"-\" * 55)\n",
    "        \n",
    "        for engine_name, stats in performance_stats.items():\n",
    "            print(f\"{engine_name:<12} {stats['avg_search_time']:<12.3f} \"\n",
    "                  f\"{stats['avg_results_count']:<12.1f} {stats['avg_relevance_score']:<15.3f}\")\n",
    "else:\n",
    "    print(\"‚ùå –ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –¥–≤–∏–∂–∫–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéØ –ê–Ω–∞–ª–∏–∑ –ø–æ–∫—Ä—ã—Ç–∏—è –∏ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\n",
      "==================================================\n",
      "\n",
      "üìä –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–æ–≤–∞—Ä–æ–≤ –ø–æ –≥—Ä—É–ø–ø–∞–º:\n",
      "   –ê–í–ê–ù–°–û–í–´–ô –û–¢–ß–ï–¢: 14704 (11.3%)\n",
      "   –ó–∞–ø–∞—Å–Ω—ã–µ —á–∞—Å—Ç–∏ –∫ –≥—Ä—É–∑–æ–≤—ã–º –∞–≤—Ç–æ–º–æ–±–∏–ª—è–º: 7716 (5.9%)\n",
      "   –ó–∞–ø–∞—Å–Ω—ã–µ —á–∞—Å—Ç–∏ –∫ —Ç—Ä–∞–∫—Ç–æ—Ä–∞–º, —Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ–π –∏ –¥–æ—Ä–æ–∂–Ω–æ–π —Ç–µ—Ö–Ω–∏–∫–µ: 5175 (4.0%)\n",
      "   –ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç —Å–ª–µ—Å–∞—Ä–Ω–æ-–º–æ–Ω—Ç–∞–∂–Ω—ã–π: 3717 (2.9%)\n",
      "   –û–¥–µ–∂–¥–∞ —Å–ø–µ—Ü–∏–∞–ª—å–Ω–∞—è –ª–µ—Ç–Ω—è—è: 2886 (2.2%)\n",
      "   –û–¥–µ–∂–¥–∞ —Å–ø–µ—Ü–∏–∞–ª—å–Ω–∞—è –∑–∏–º–Ω—è—è: 2242 (1.7%)\n",
      "   –ó–ò–ü –∫ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—é Canrig: 1621 (1.2%)\n",
      "   –ó–ò–ü –∫ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—é Tesco: 1487 (1.1%)\n",
      "   –ü–µ—Ä–µ–≤–æ–¥–Ω–∏–∫–∏ –¥–ª—è –±—É—Ä–∏–ª—å–Ω—ã—Ö –∫–æ–ª–æ–Ω–Ω: 1408 (1.1%)\n",
      "   –ó–ò–ü –∫ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—é National Oilwell Varco (NOV): 1343 (1.0%)\n",
      "\n",
      "üéØ –ü–æ–∫—Ä—ã—Ç–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞:\n",
      "   –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤ –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞—Ö: 16\n",
      "   –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–≤–∞—Ä–æ–≤: 130303\n",
      "   –ü–æ–∫—Ä—ã—Ç–∏–µ: 0.0%\n",
      "\n",
      "üí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —É–ª—É—á—à–µ–Ω–∏—é:\n",
      "   - –ù–∏–∑–∫–æ–µ –ø–æ–∫—Ä—ã—Ç–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞. –†–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ –ø–æ–∏—Å–∫–æ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤\n",
      "   - –†–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è –Ω–∞ —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã—Ö –¥–ª—è –¥–æ–º–µ–Ω–∞ –¥–∞–Ω–Ω—ã—Ö\n",
      "   - –î–æ–±–∞–≤—å—Ç–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫—É—é –æ–±—Ä–∞—Ç–Ω—É—é —Å–≤—è–∑—å –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏\n"
     ]
    }
   ],
   "source": [
    "# –ê–Ω–∞–ª–∏–∑ –ø–æ–∫—Ä—ã—Ç–∏—è –∏ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\n",
    "print(\"\\nüéØ –ê–Ω–∞–ª–∏–∑ –ø–æ–∫—Ä—ã—Ç–∏—è –∏ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "if available_engines and len(processed_data) > 0:\n",
    "    # –ê–Ω–∞–ª–∏–∑ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –ø–æ –≥—Ä—É–ø–ø–∞–º —Ç–æ–≤–∞—Ä–æ–≤\n",
    "    if '–ì—Ä—É–ø–ø–∞' in processed_data.columns:\n",
    "        group_distribution = processed_data['–ì—Ä—É–ø–ø–∞'].value_counts()\n",
    "        print(f\"\\nüìä –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–æ–≤–∞—Ä–æ–≤ –ø–æ –≥—Ä—É–ø–ø–∞–º:\")\n",
    "        for group, count in group_distribution.head(10).items():\n",
    "            percentage = (count / len(processed_data)) * 100\n",
    "            print(f\"   {group}: {count} ({percentage:.1f}%)\")\n",
    "    \n",
    "    # –ê–Ω–∞–ª–∏–∑ —É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ–∏—Å–∫–∞\n",
    "    engine_name = list(available_engines.keys())[0]\n",
    "    unique_results = set()\n",
    "    \n",
    "    for query in example_queries[:5]:\n",
    "        results = search_analogs(query, engine_name, top_k=5)\n",
    "        for result in results:\n",
    "            unique_results.add(result['index'])\n",
    "    \n",
    "    coverage = len(unique_results) / len(processed_data) * 100\n",
    "    print(f\"\\nüéØ –ü–æ–∫—Ä—ã—Ç–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞:\")\n",
    "    print(f\"   –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤ –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞—Ö: {len(unique_results)}\")\n",
    "    print(f\"   –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–≤–∞—Ä–æ–≤: {len(processed_data)}\")\n",
    "    print(f\"   –ü–æ–∫—Ä—ã—Ç–∏–µ: {coverage:.1f}%\")\n",
    "    \n",
    "    # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —É–ª—É—á—à–µ–Ω–∏—é\n",
    "    print(f\"\\nüí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —É–ª—É—á—à–µ–Ω–∏—é:\")\n",
    "    \n",
    "    if coverage < 20:\n",
    "        print(\"   - –ù–∏–∑–∫–æ–µ –ø–æ–∫—Ä—ã—Ç–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞. –†–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ –ø–æ–∏—Å–∫–æ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤\")\n",
    "    \n",
    "    if len(available_engines) == 1:\n",
    "        print(\"   - –ù–∞—Å—Ç—Ä–æ–π—Ç–µ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–æ–∏—Å–∫–æ–≤—ã–µ –¥–≤–∏–∂–∫–∏ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è\")\n",
    "    \n",
    "    if not parameter_extractor:\n",
    "        print(\"   - –ù–∞—Å—Ç—Ä–æ–π—Ç–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –¥–ª—è –±–æ–ª–µ–µ —Ç–æ—á–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞\")\n",
    "    \n",
    "    print(\"   - –†–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è –Ω–∞ —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã—Ö –¥–ª—è –¥–æ–º–µ–Ω–∞ –¥–∞–Ω–Ω—ã—Ö\")\n",
    "    print(\"   - –î–æ–±–∞–≤—å—Ç–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫—É—é –æ–±—Ä–∞—Ç–Ω—É—é —Å–≤—è–∑—å –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –ø–æ–∫—Ä—ã—Ç–∏—è\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ–±—É—á–µ–Ω–Ω–æ–π —Å–∏—Å—Ç–µ–º—ã –ø–æ–∏—Å–∫–∞\n",
    "\n",
    "–°–æ—Ö—Ä–∞–Ω—è–µ–º –≤—Å–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã —Å–∏—Å—Ç–µ–º—ã –¥–ª—è –ø–æ—Å–ª–µ–¥—É—é—â–µ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ–±—É—á–µ–Ω–Ω–æ–π —Å–∏—Å—Ç–µ–º—ã –ø–æ–∏—Å–∫–∞...\n",
      "üìÅ –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è: ../../models/analog_search\n",
      "üè∑Ô∏è –í–µ—Ä—Å–∏—è –º–æ–¥–µ–ª–∏: v20250719_121641\n",
      "‚úÖ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: configs_v20250719_121641.pkl\n",
      "üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–µ—Ä–∏–∞–ª–∏–∑—É–µ–º–æ—Å—Ç–∏ —Ñ—É–Ω–∫—Ü–∏–π...\n",
      "‚úÖ enhanced_simple_preprocess —Å–µ—Ä–∏–∞–ª–∏–∑—É–µ—Ç—Å—è —É—Å–ø–µ—à–Ω–æ\n",
      "‚ö†Ô∏è final_preprocess_function –Ω–µ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è (–º–æ–∂–µ—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç—å –ª–æ–∫–∞–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏)\n",
      "‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏: cannot pickle '_thread.RLock' object\n",
      "üìã –ü–æ–¥—Ä–æ–±–Ω–æ—Å—Ç–∏ –æ—à–∏–±–∫–∏: Traceback (most recent call last):\n",
      "  File \"/var/folders/h8/fhfvbn0j38nd4r3z3s719g1m0000gn/T/ipykernel_14907/3689836757.py\", line 83, in <module>\n",
      "    pickle.dump(preprocessing_components, f)\n",
      "TypeError: cannot pickle '_thread.RLock' object\n",
      "\n",
      "‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –ø–æ–∏—Å–∫–æ–≤—ã—Ö –¥–≤–∏–∂–∫–æ–≤: cannot pickle '_thread.RLock' object\n",
      "‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: processed_data_v20250719_121641.pkl\n",
      "üìä –†–∞–∑–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö: 130303 –∑–∞–ø–∏—Å–µ–π, 7 —Å—Ç–æ–ª–±—Ü–æ–≤\n",
      "‚úÖ –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ —Å–∏—Å—Ç–µ–º—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: system_metadata_v20250719_121641.json\n",
      "‚úÖ –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: README_v20250719_121641.md\n",
      "\n",
      "üéâ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!\n",
      "üìÅ –í—Å–µ —Ñ–∞–π–ª—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: ../../models/analog_search\n",
      "üè∑Ô∏è –í–µ—Ä—Å–∏—è –º–æ–¥–µ–ª–∏: v20250719_121641\n",
      "\n",
      "üìã –°–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã:\n",
      "   ‚Ä¢ README_v20250719_121641.md (0.0 MB)\n",
      "   ‚Ä¢ search_engines_v20250719_121641.pkl (479.4 MB)\n",
      "   ‚Ä¢ processed_data_v20250719_121641.pkl (24.7 MB)\n",
      "   ‚Ä¢ preprocessing_v20250719_121641.pkl (457.6 MB)\n",
      "   ‚Ä¢ configs_v20250719_121641.pkl (0.0 MB)\n",
      "   ‚Ä¢ system_metadata_v20250719_121641.json (6.0 MB)\n",
      "\n",
      "üí° –î–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –º–æ–¥–µ–ª–∏ –∑–∞–ø—É—Å—Ç–∏—Ç–µ notebook: analog_search_production.ipynb\n",
      "üîß –ü–µ—Ä–µ–¥–∞–π—Ç–µ –≤–µ—Ä—Å–∏—é –º–æ–¥–µ–ª–∏: v20250719_121641\n",
      "‚úÖ –í–µ—Ä—Å–∏—è –º–æ–¥–µ–ª–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤: latest_version.txt\n",
      "\n",
      "üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö —Ñ—É–Ω–∫—Ü–∏–π...\n",
      "‚ùå –û—à–∏–±–∫–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è: Ran out of input\n"
     ]
    }
   ],
   "source": [
    "# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ–±—É—á–µ–Ω–Ω–æ–π —Å–∏—Å—Ç–µ–º—ã –ø–æ–∏—Å–∫–∞ –∞–Ω–∞–ª–æ–≥–æ–≤\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "print(\"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ–±—É—á–µ–Ω–Ω–æ–π —Å–∏—Å—Ç–µ–º—ã –ø–æ–∏—Å–∫–∞...\")\n",
    "\n",
    "# –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π\n",
    "models_dir = Path(\"../../models/analog_search\")\n",
    "models_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# –í—Ä–µ–º–µ–Ω–Ω–∞—è –º–µ—Ç–∫–∞ –¥–ª—è –≤–µ—Ä—Å–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏—è\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "model_version = f\"v{timestamp}\"\n",
    "\n",
    "print(f\"üìÅ –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è: {models_dir}\")\n",
    "print(f\"üè∑Ô∏è –í–µ—Ä—Å–∏—è –º–æ–¥–µ–ª–∏: {model_version}\")\n",
    "\n",
    "# –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è\n",
    "system_data = {\n",
    "    'version': model_version,\n",
    "    'created_at': datetime.now().isoformat(),\n",
    "    'dataset_info': {\n",
    "        'total_records': len(processed_data) if 'processed_data' in locals() else 0,\n",
    "        'main_column': main_name_column if 'main_name_column' in locals() else None,\n",
    "        'columns': list(processed_data.columns) if 'processed_data' in locals() else []\n",
    "    },\n",
    "    'preprocessing_stats': processing_stats if 'processing_stats' in locals() else None,\n",
    "    'available_engines': list(available_engines.keys()) if 'available_engines' in locals() else [],\n",
    "    'spacy_available': spacy_available if 'spacy_available' in locals() else False,\n",
    "    'preprocessing_errors': preprocessing_errors if 'preprocessing_errors' in locals() else []\n",
    "}\n",
    "\n",
    "# 1. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π\n",
    "configs_path = models_dir / f\"configs_{model_version}.pkl\"\n",
    "try:\n",
    "    configs = {\n",
    "        'cleaning_config': cleaning_config if 'cleaning_config' in locals() else None,\n",
    "        'normalizer_config': normalizer_config if 'normalizer_config' in locals() else None,\n",
    "        'lemmatizer_config': lemmatizer_config if 'lemmatizer_config' in locals() else None,\n",
    "        'preprocessor_config': preprocessor_config if 'preprocessor_config' in locals() else None\n",
    "    }\n",
    "    \n",
    "    with open(configs_path, 'wb') as f:\n",
    "        pickle.dump(configs, f)\n",
    "    print(f\"‚úÖ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {configs_path.name}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π: {e}\")\n",
    "\n",
    "# 2. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏\n",
    "preprocessing_path = models_dir / f\"preprocessing_{model_version}.pkl\"\n",
    "try:\n",
    "    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–µ—Ä–∏–∞–ª–∏–∑—É–µ–º–æ—Å—Ç—å —Ñ—É–Ω–∫—Ü–∏–π –ø–µ—Ä–µ–¥ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º\n",
    "    print(\"üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–µ—Ä–∏–∞–ª–∏–∑—É–µ–º–æ—Å—Ç–∏ —Ñ—É–Ω–∫—Ü–∏–π...\")\n",
    "    \n",
    "    # –¢–µ—Å—Ç–∏—Ä—É–µ–º —Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏—é enhanced_simple_preprocess\n",
    "    if 'enhanced_simple_preprocess' in locals():\n",
    "        try:\n",
    "            test_pickle = pickle.dumps(enhanced_simple_preprocess)\n",
    "            print(\"‚úÖ enhanced_simple_preprocess —Å–µ—Ä–∏–∞–ª–∏–∑—É–µ—Ç—Å—è —É—Å–ø–µ—à–Ω–æ\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå enhanced_simple_preprocess –Ω–µ —Å–µ—Ä–∏–∞–ª–∏–∑—É–µ—Ç—Å—è: {e}\")\n",
    "    \n",
    "    preprocessing_components = {\n",
    "        'text_cleaner': text_cleaner if 'text_cleaner' in locals() else None,\n",
    "        'text_normalizer': text_normalizer if 'text_normalizer' in locals() else None,\n",
    "        'lemmatizer': lemmatizer if 'lemmatizer' in locals() else None,\n",
    "        'preprocessor': preprocessor if 'preprocessor' in locals() else None,\n",
    "        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–æ–ª—å–∫–æ –≥–ª–æ–±–∞–ª—å–Ω—É—é —Ñ—É–Ω–∫—Ü–∏—é, –∫–æ—Ç–æ—Ä–∞—è —Å–µ—Ä–∏–∞–ª–∏–∑—É–µ—Ç—Å—è\n",
    "        'enhanced_simple_preprocess': enhanced_simple_preprocess if 'enhanced_simple_preprocess' in locals() else None,\n",
    "        # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏\n",
    "        'function_info': {\n",
    "            'enhanced_simple_preprocess_type': str(type(enhanced_simple_preprocess)) if 'enhanced_simple_preprocess' in locals() else None,\n",
    "            'enhanced_simple_preprocess_module': getattr(enhanced_simple_preprocess, '__module__', None) if 'enhanced_simple_preprocess' in locals() else None,\n",
    "            'enhanced_simple_preprocess_name': getattr(enhanced_simple_preprocess, '__name__', None) if 'enhanced_simple_preprocess' in locals() else None,\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # –ò—Å–∫–ª—é—á–∞–µ–º final_preprocess_function, —Ç–∞–∫ –∫–∞–∫ –æ–Ω–∞ –º–æ–∂–µ—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç—å –ª–æ–∫–∞–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏\n",
    "    print(\"‚ö†Ô∏è final_preprocess_function –Ω–µ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è (–º–æ–∂–µ—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç—å –ª–æ–∫–∞–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏)\")\n",
    "    \n",
    "    with open(preprocessing_path, 'wb') as f:\n",
    "        pickle.dump(preprocessing_components, f)\n",
    "    print(f\"‚úÖ –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {preprocessing_path.name}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏: {e}\")\n",
    "    import traceback\n",
    "    print(f\"üìã –ü–æ–¥—Ä–æ–±–Ω–æ—Å—Ç–∏ –æ—à–∏–±–∫–∏: {traceback.format_exc()}\")\n",
    "\n",
    "# 3. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø–æ–∏—Å–∫–æ–≤—ã—Ö –¥–≤–∏–∂–∫–æ–≤\n",
    "if 'available_engines' in locals() and available_engines:\n",
    "    engines_path = models_dir / f\"search_engines_{model_version}.pkl\"\n",
    "    try:\n",
    "        with open(engines_path, 'wb') as f:\n",
    "            pickle.dump(available_engines, f)\n",
    "        print(f\"‚úÖ –ü–æ–∏—Å–∫–æ–≤—ã–µ –¥–≤–∏–∂–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {engines_path.name}\")\n",
    "        \n",
    "        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–ª—è –±–æ–ª—å—à–∏—Ö –º–æ–¥–µ–ª–µ–π\n",
    "        for engine_name, engine in available_engines.items():\n",
    "            if hasattr(engine, 'save_model'):\n",
    "                try:\n",
    "                    engine_model_path = models_dir / f\"{engine_name}_model_{model_version}.pkl\"\n",
    "                    engine.save_model(str(engine_model_path))\n",
    "                    print(f\"‚úÖ –ú–æ–¥–µ–ª—å {engine_name} —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –æ—Ç–¥–µ–ª—å–Ω–æ: {engine_model_path.name}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –º–æ–¥–µ–ª—å {engine_name}: {e}\")\n",
    "                    \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –ø–æ–∏—Å–∫–æ–≤—ã—Ö –¥–≤–∏–∂–∫–æ–≤: {e}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è –ü–æ–∏—Å–∫–æ–≤—ã–µ –¥–≤–∏–∂–∫–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è\")\n",
    "\n",
    "# 4. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n",
    "if 'processed_data' in locals() and len(processed_data) > 0:\n",
    "    data_path = models_dir / f\"processed_data_{model_version}.pkl\"\n",
    "    try:\n",
    "        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–æ–ª—å–∫–æ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ —Å—Ç–æ–ª–±—Ü—ã –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –º–µ—Å—Ç–∞\n",
    "        essential_columns = [main_name_column, 'processed_name'] if 'main_name_column' in locals() else []\n",
    "        other_columns = [col for col in processed_data.columns if col not in essential_columns]\n",
    "        all_columns = essential_columns + other_columns\n",
    "        \n",
    "        essential_data = processed_data[all_columns].copy()\n",
    "        \n",
    "        with open(data_path, 'wb') as f:\n",
    "            pickle.dump(essential_data, f)\n",
    "        print(f\"‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {data_path.name}\")\n",
    "        print(f\"üìä –†–∞–∑–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö: {len(essential_data)} –∑–∞–ø–∏—Å–µ–π, {len(essential_data.columns)} —Å—Ç–æ–ª–±—Ü–æ–≤\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö: {e}\")\n",
    "\n",
    "# 5. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö —Å–∏—Å—Ç–µ–º—ã\n",
    "metadata_path = models_dir / f\"system_metadata_{model_version}.json\"\n",
    "try:\n",
    "    with open(metadata_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(system_data, f, ensure_ascii=False, indent=2, default=str)\n",
    "    print(f\"‚úÖ –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ —Å–∏—Å—Ç–µ–º—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {metadata_path.name}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö: {e}\")\n",
    "\n",
    "# 6. –°–æ–∑–¥–∞–Ω–∏–µ —Ñ–∞–π–ª–∞ —Å –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è–º–∏ –ø–æ –∑–∞–≥—Ä—É–∑–∫–µ\n",
    "readme_path = models_dir / f\"README_{model_version}.md\"\n",
    "try:\n",
    "    dataset_size = len(processed_data) if 'processed_data' in locals() else 'N/A'\n",
    "    engines_list = ', '.join(available_engines.keys()) if 'available_engines' in locals() else 'N/A'\n",
    "    \n",
    "    readme_content = f\"\"\"# –°–∏—Å—Ç–µ–º–∞ –ø–æ–∏—Å–∫–∞ –∞–Ω–∞–ª–æ–≥–æ–≤ - {model_version}\n",
    "\n",
    "## –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª–∏\n",
    "- **–í–µ—Ä—Å–∏—è**: {model_version}\n",
    "- **–°–æ–∑–¥–∞–Ω–∞**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "- **–ó–∞–ø–∏—Å–µ–π –≤ –¥–∞—Ç–∞—Å–µ—Ç–µ**: {dataset_size}\n",
    "- **–î–æ—Å—Ç—É–ø–Ω—ã–µ –¥–≤–∏–∂–∫–∏**: {engines_list}\n",
    "\n",
    "## –§–∞–π–ª—ã –º–æ–¥–µ–ª–∏\n",
    "- `configs_{model_version}.pkl` - –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤\n",
    "- `preprocessing_{model_version}.pkl` - –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏\n",
    "- `search_engines_{model_version}.pkl` - –ü–æ–∏—Å–∫–æ–≤—ã–µ –¥–≤–∏–∂–∫–∏\n",
    "- `processed_data_{model_version}.pkl` - –û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ\n",
    "- `system_metadata_{model_version}.json` - –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ —Å–∏—Å—Ç–µ–º—ã\n",
    "\n",
    "## –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏\n",
    "```python\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "models_dir = Path(\"models/analog_search\")\n",
    "version = \"{model_version}\"\n",
    "\n",
    "# –ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤\n",
    "with open(models_dir / f\"preprocessing_{{version}}.pkl\", 'rb') as f:\n",
    "    preprocessing = pickle.load(f)\n",
    "\n",
    "with open(models_dir / f\"search_engines_{{version}}.pkl\", 'rb') as f:\n",
    "    engines = pickle.load(f)\n",
    "\n",
    "with open(models_dir / f\"processed_data_{{version}}.pkl\", 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "```\n",
    "\n",
    "## –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ\n",
    "–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ notebook `analog_search_production.ipynb` –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –º–æ–¥–µ–ª–∏.\n",
    "\"\"\"\n",
    "    \n",
    "    with open(readme_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(readme_content)\n",
    "    print(f\"‚úÖ –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {readme_path.name}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–π: {e}\")\n",
    "\n",
    "# –ò—Ç–æ–≥–æ–≤—ã–π –æ—Ç—á–µ—Ç\n",
    "print(f\"\\nüéâ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!\")\n",
    "print(f\"üìÅ –í—Å–µ —Ñ–∞–π–ª—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {models_dir}\")\n",
    "print(f\"üè∑Ô∏è –í–µ—Ä—Å–∏—è –º–æ–¥–µ–ª–∏: {model_version}\")\n",
    "print(f\"\\nüìã –°–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã:\")\n",
    "for file_path in models_dir.glob(f\"*{model_version}*\"):\n",
    "    file_size = file_path.stat().st_size / (1024*1024)  # MB\n",
    "    print(f\"   ‚Ä¢ {file_path.name} ({file_size:.1f} MB)\")\n",
    "\n",
    "print(f\"\\nüí° –î–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –º–æ–¥–µ–ª–∏ –∑–∞–ø—É—Å—Ç–∏—Ç–µ notebook: analog_search_production.ipynb\")\n",
    "print(f\"üîß –ü–µ—Ä–µ–¥–∞–π—Ç–µ –≤–µ—Ä—Å–∏—é –º–æ–¥–µ–ª–∏: {model_version}\")\n",
    "\n",
    "# –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤–µ—Ä—Å–∏—é –º–æ–¥–µ–ª–∏ –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ production notebook\n",
    "latest_version_path = models_dir / \"latest_version.txt\"\n",
    "try:\n",
    "    with open(latest_version_path, 'w') as f:\n",
    "        f.write(model_version)\n",
    "    print(f\"‚úÖ –í–µ—Ä—Å–∏—è –º–æ–¥–µ–ª–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤: {latest_version_path.name}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤–µ—Ä—Å–∏—é: {e}\")\n",
    "\n",
    "# –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≥—Ä—É–∑–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö —Ñ—É–Ω–∫—Ü–∏–π\n",
    "print(f\"\\nüß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö —Ñ—É–Ω–∫—Ü–∏–π...\")\n",
    "try:\n",
    "    test_preprocessing_path = models_dir / f\"preprocessing_{model_version}.pkl\"\n",
    "    with open(test_preprocessing_path, 'rb') as f:\n",
    "        test_components = pickle.load(f)\n",
    "    \n",
    "    test_function = test_components.get('enhanced_simple_preprocess')\n",
    "    if test_function:\n",
    "        test_result = test_function(\"–¢–µ—Å—Ç–æ–≤—ã–π —Ç–µ–∫—Å—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏\")\n",
    "        print(f\"‚úÖ –§—É–Ω–∫—Ü–∏—è –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ä–∞–±–æ—Ç–∞–µ—Ç: '{test_result}'\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è –§—É–Ω–∫—Ü–∏—è –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞\")\n",
    "        \n",
    "    function_info = test_components.get('function_info', {})\n",
    "    if function_info:\n",
    "        print(f\"üìã –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏–∏: {function_info}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå –û—à–∏–±–∫–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. –í—ã–≤–æ–¥—ã –∏ –∑–∞–∫–ª—é—á–µ–Ω–∏–µ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ –ò–¢–û–ì–û–í–´–ï –í–´–í–û–î–´ –ü–û –°–ò–°–¢–ï–ú–ï –ü–û–ò–°–ö–ê –ê–ù–ê–õ–û–ì–û–í\n",
      "======================================================================\n",
      "\n",
      "üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö:\n",
      "   –ó–∞–≥—Ä—É–∂–µ–Ω–æ –∑–∞–ø–∏—Å–µ–π: 130303\n",
      "   –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –∑–∞–ø–∏—Å–µ–π: 130303\n",
      "   –û—Å–Ω–æ–≤–Ω–æ–π —Å—Ç–æ–ª–±–µ—Ü: –ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ\n",
      "\n",
      "üîß –ù–∞—Å—Ç—Ä–æ–µ–Ω–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã:\n",
      "   ‚úÖ –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞\n",
      "   ‚úÖ –ù–µ—á–µ—Ç–∫–∏–π –ø–æ–∏—Å–∫\n",
      "   ‚úÖ –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫\n",
      "   ‚úÖ –ì–∏–±—Ä–∏–¥–Ω—ã–π –ø–æ–∏—Å–∫\n",
      "   ‚úÖ –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤\n",
      "\n",
      "üéØ –í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ —Å–∏—Å—Ç–µ–º—ã:\n",
      "   üìù –ü–æ–∏—Å–∫ –∞–Ω–∞–ª–æ–≥–æ–≤ –ø–æ —Ç–µ–∫—Å—Ç–æ–≤–æ–º—É –æ–ø–∏—Å–∞–Ω–∏—é\n",
      "   üîç –ú–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –∞–ª–≥–æ—Ä–∏—Ç–º—ã –ø–æ–∏—Å–∫–∞\n",
      "   üìä –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏ –∞–Ω–∞–ª–∏–∑ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤\n",
      "   ‚öñÔ∏è  –û—Ü–µ–Ω–∫–∞ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\n",
      "   üìã –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏—è —Ç–æ–≤–∞—Ä–æ–≤\n",
      "\n",
      "üöÄ –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–æ–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ:\n",
      "   ‚Ä¢ –ü–æ–∏—Å–∫ –∑–∞–º–µ–Ω–∏—Ç–µ–ª–µ–π –¥–ª—è —Å–Ω—è—Ç—ã—Ö —Å –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–∞ —Ç–æ–≤–∞—Ä–æ–≤\n",
      "   ‚Ä¢ –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –æ—Ç —Ä–∞–∑–Ω—ã—Ö –ø–æ—Å—Ç–∞–≤—â–∏–∫–æ–≤\n",
      "   ‚Ä¢ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏—è –Ω–æ–≤—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤\n",
      "   ‚Ä¢ –ê–Ω–∞–ª–∏–∑ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π\n",
      "   ‚Ä¢ –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —Å–∫–ª–∞–¥—Å–∫–∏—Ö –∑–∞–ø–∞—Å–æ–≤\n",
      "\n",
      "üìà –ù–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è —Ä–∞–∑–≤–∏—Ç–∏—è:\n",
      "   ‚Ä¢ –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å –≤–Ω–µ—à–Ω–∏–º–∏ –∫–∞—Ç–∞–ª–æ–≥–∞–º–∏ —Ç–æ–≤–∞—Ä–æ–≤\n",
      "   ‚Ä¢ –ú–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏—Ö –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è—Ö\n",
      "   ‚Ä¢ –ê–Ω–∞–ª–∏–∑ —Ü–µ–Ω–æ–≤—ã—Ö —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫\n",
      "   ‚Ä¢ API –¥–ª—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ —Å ERP-—Å–∏—Å—Ç–µ–º–∞–º–∏\n",
      "   ‚Ä¢ –í–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è –∫–æ–Ω–µ—á–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π\n",
      "\n",
      "‚úÖ –°–∏—Å—Ç–µ–º–∞ –ø–æ–∏—Å–∫–∞ –∞–Ω–∞–ª–æ–≥–æ–≤ –≥–æ—Ç–æ–≤–∞ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é!\n",
      "üìö –î–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Å–ø—Ä–∞–≤–∫–∏ –ø–æ API –æ–±—Ä–∞—Ç–∏—Ç–µ—Å—å –∫ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ SAMe\n",
      "\n",
      "üíæ –û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: ../../data/output/processed_nomenclature.csv\n",
      "\n",
      "üïê –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω: 2025-07-19 12:16:44\n"
     ]
    }
   ],
   "source": [
    "# –ò—Ç–æ–≥–æ–≤—ã–µ –≤—ã–≤–æ–¥—ã\n",
    "print(\"üéØ –ò–¢–û–ì–û–í–´–ï –í–´–í–û–î–´ –ü–û –°–ò–°–¢–ï–ú–ï –ü–û–ò–°–ö–ê –ê–ù–ê–õ–û–ì–û–í\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö:\")\n",
    "print(f\"   –ó–∞–≥—Ä—É–∂–µ–Ω–æ –∑–∞–ø–∏—Å–µ–π: {len(data) if 'data' in locals() else 0}\")\n",
    "print(f\"   –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –∑–∞–ø–∏—Å–µ–π: {len(processed_data) if 'processed_data' in locals() else 0}\")\n",
    "print(f\"   –û—Å–Ω–æ–≤–Ω–æ–π —Å—Ç–æ–ª–±–µ—Ü: {main_name_column if 'main_name_column' in locals() else 'N/A'}\")\n",
    "\n",
    "print(f\"\\nüîß –ù–∞—Å—Ç—Ä–æ–µ–Ω–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã:\")\n",
    "components_status = {\n",
    "    '–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞': '‚úÖ' if 'preprocessor' in locals() and preprocessor else '‚ùå',\n",
    "    '–ù–µ—á–µ—Ç–∫–∏–π –ø–æ–∏—Å–∫': '‚úÖ' if 'fuzzy_engine' in locals() and fuzzy_engine else '‚ùå',\n",
    "    '–°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫': '‚úÖ' if 'semantic_engine' in locals() and semantic_engine else '‚ùå',\n",
    "    '–ì–∏–±—Ä–∏–¥–Ω—ã–π –ø–æ–∏—Å–∫': '‚úÖ' if 'hybrid_engine' in locals() and hybrid_engine else '‚ùå',\n",
    "    '–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤': '‚úÖ' if 'parameter_extractor' in locals() and parameter_extractor else '‚ùå'\n",
    "}\n",
    "\n",
    "for component, status in components_status.items():\n",
    "    print(f\"   {status} {component}\")\n",
    "\n",
    "print(f\"\\nüéØ –í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ —Å–∏—Å—Ç–µ–º—ã:\")\n",
    "print(f\"   üìù –ü–æ–∏—Å–∫ –∞–Ω–∞–ª–æ–≥–æ–≤ –ø–æ —Ç–µ–∫—Å—Ç–æ–≤–æ–º—É –æ–ø–∏—Å–∞–Ω–∏—é\")\n",
    "print(f\"   üîç –ú–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –∞–ª–≥–æ—Ä–∏—Ç–º—ã –ø–æ–∏—Å–∫–∞\")\n",
    "print(f\"   üìä –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏ –∞–Ω–∞–ª–∏–∑ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤\")\n",
    "print(f\"   ‚öñÔ∏è  –û—Ü–µ–Ω–∫–∞ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\")\n",
    "print(f\"   üìã –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏—è —Ç–æ–≤–∞—Ä–æ–≤\")\n",
    "\n",
    "print(f\"\\nüöÄ –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–æ–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ:\")\n",
    "print(f\"   ‚Ä¢ –ü–æ–∏—Å–∫ –∑–∞–º–µ–Ω–∏—Ç–µ–ª–µ–π –¥–ª—è —Å–Ω—è—Ç—ã—Ö —Å –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–∞ —Ç–æ–≤–∞—Ä–æ–≤\")\n",
    "print(f\"   ‚Ä¢ –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –æ—Ç —Ä–∞–∑–Ω—ã—Ö –ø–æ—Å—Ç–∞–≤—â–∏–∫–æ–≤\")\n",
    "print(f\"   ‚Ä¢ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏—è –Ω–æ–≤—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤\")\n",
    "print(f\"   ‚Ä¢ –ê–Ω–∞–ª–∏–∑ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π\")\n",
    "print(f\"   ‚Ä¢ –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —Å–∫–ª–∞–¥—Å–∫–∏—Ö –∑–∞–ø–∞—Å–æ–≤\")\n",
    "\n",
    "print(f\"\\nüìà –ù–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è —Ä–∞–∑–≤–∏—Ç–∏—è:\")\n",
    "print(f\"   ‚Ä¢ –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å –≤–Ω–µ—à–Ω–∏–º–∏ –∫–∞—Ç–∞–ª–æ–≥–∞–º–∏ —Ç–æ–≤–∞—Ä–æ–≤\")\n",
    "print(f\"   ‚Ä¢ –ú–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏—Ö –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è—Ö\")\n",
    "print(f\"   ‚Ä¢ –ê–Ω–∞–ª–∏–∑ —Ü–µ–Ω–æ–≤—ã—Ö —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫\")\n",
    "print(f\"   ‚Ä¢ API –¥–ª—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ —Å ERP-—Å–∏—Å—Ç–µ–º–∞–º–∏\")\n",
    "print(f\"   ‚Ä¢ –í–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è –∫–æ–Ω–µ—á–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π\")\n",
    "\n",
    "print(f\"\\n‚úÖ –°–∏—Å—Ç–µ–º–∞ –ø–æ–∏—Å–∫–∞ –∞–Ω–∞–ª–æ–≥–æ–≤ –≥–æ—Ç–æ–≤–∞ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é!\")\n",
    "print(f\"üìö –î–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Å–ø—Ä–∞–≤–∫–∏ –ø–æ API –æ–±—Ä–∞—Ç–∏—Ç–µ—Å—å –∫ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ SAMe\")\n",
    "\n",
    "# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)\n",
    "if 'processed_data' in locals() and len(processed_data) > 0:\n",
    "    try:\n",
    "        output_path = Path(\"../../data/output/processed_nomenclature.csv\")\n",
    "        output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        processed_data.to_csv(output_path, index=False)\n",
    "        print(f\"\\nüíæ –û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {output_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –¥–∞–Ω–Ω—ã–µ: {e}\")\n",
    "\n",
    "print(f\"\\nüïê –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}