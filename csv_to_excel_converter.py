#!/usr/bin/env python3
"""
–ü—Ä–æ—Å—Ç–æ–π –∫–æ–Ω–≤–µ—Ä—Ç–µ—Ä CSV –≤ Excel —Å —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ–º
"""

import pandas as pd
import argparse
import logging
from pathlib import Path
from datetime import datetime
import os
from openpyxl import Workbook
from openpyxl.styles import Font, PatternFill, Alignment, Border, Side
from openpyxl.utils.dataframe import dataframe_to_rows

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


def create_excel_with_formatting(csv_file: str, excel_file: str, metadata: dict = None) -> bool:
    """–°–æ–∑–¥–∞–Ω–∏–µ Excel —Ñ–∞–π–ª–∞ —Å —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ–º –∏–∑ CSV"""
    try:
        logger.info(f"Converting {csv_file} to {excel_file}...")
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º CSV –¥–∞–Ω–Ω—ã–µ
        df = pd.read_csv(csv_file)
        logger.info(f"Loaded {len(df)} records from CSV")
        
        # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é –∫–Ω–∏–≥—É Excel
        wb = Workbook()
        
        # –£–¥–∞–ª—è–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –ª–∏—Å—Ç
        if 'Sheet' in wb.sheetnames:
            wb.remove(wb['Sheet'])
        
        # === –û–°–ù–û–í–ù–´–ï –î–ê–ù–ù–´–ï (—Ä–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ –ª–∏—Å—Ç—ã –µ—Å–ª–∏ –º–Ω–æ–≥–æ –¥–∞–Ω–Ω—ã—Ö) ===
        max_rows_per_sheet = 1000000  # –û—Å—Ç–∞–≤–ª—è–µ–º –∑–∞–ø–∞—Å –¥–ª—è Excel
        total_rows = len(df)

        if total_rows <= max_rows_per_sheet:
            # –û–¥–∏–Ω –ª–∏—Å—Ç
            ws_data = wb.create_sheet("–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞")

            # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ
            for r in dataframe_to_rows(df, index=False, header=True):
                ws_data.append(r)

            data_sheets = [ws_data]
        else:
            # –ù–µ—Å–∫–æ–ª—å–∫–æ –ª–∏—Å—Ç–æ–≤
            data_sheets = []
            num_sheets = (total_rows + max_rows_per_sheet - 1) // max_rows_per_sheet

            logger.info(f"Data too large ({total_rows:,} rows), splitting into {num_sheets} sheets")

            for sheet_num in range(num_sheets):
                start_idx = sheet_num * max_rows_per_sheet
                end_idx = min(start_idx + max_rows_per_sheet, total_rows)

                sheet_name = f"–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞ {sheet_num + 1}"
                ws_data = wb.create_sheet(sheet_name)

                # –ü–æ–ª—É—á–∞–µ–º —á–∞—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö
                df_chunk = df.iloc[start_idx:end_idx]

                # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ
                for r in dataframe_to_rows(df_chunk, index=False, header=True):
                    ws_data.append(r)

                data_sheets.append(ws_data)
                logger.info(f"Created sheet {sheet_num + 1}: rows {start_idx:,}-{end_idx:,}")
        
        # –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≤—Å–µ—Ö –ª–∏—Å—Ç–æ–≤ —Å –¥–∞–Ω–Ω—ã–º–∏
        header_font = Font(bold=True, color="FFFFFF")
        header_fill = PatternFill(start_color="366092", end_color="366092", fill_type="solid")
        header_alignment = Alignment(horizontal="center", vertical="center")
        high_similarity_fill = PatternFill(start_color="90EE90", end_color="90EE90", fill_type="solid")

        for ws_data in data_sheets:
            # –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤
            for col in range(1, len(df.columns) + 1):
                cell = ws_data.cell(row=1, column=col)
                cell.font = header_font
                cell.fill = header_fill
                cell.alignment = header_alignment

            # –ê–≤—Ç–æ–ø–æ–¥–±–æ—Ä —à–∏—Ä–∏–Ω—ã –∫–æ–ª–æ–Ω–æ–∫ (—Ç–æ–ª—å–∫–æ –¥–ª—è –ø–µ—Ä–≤–æ–≥–æ –ª–∏—Å—Ç–∞, —á—Ç–æ–±—ã —É—Å–∫–æ—Ä–∏—Ç—å)
            if ws_data == data_sheets[0]:
                for column in ws_data.columns:
                    max_length = 0
                    column_letter = column[0].column_letter

                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ 100 —Å—Ç—Ä–æ–∫ –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏
                    for cell in list(column)[:100]:
                        try:
                            if len(str(cell.value)) > max_length:
                                max_length = len(str(cell.value))
                        except:
                            pass

                    adjusted_width = min(max_length + 2, 50)  # –ú–∞–∫—Å–∏–º—É–º 50 —Å–∏–º–≤–æ–ª–æ–≤
                    ws_data.column_dimensions[column_letter].width = adjusted_width

                    # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ç—É –∂–µ —à–∏—Ä–∏–Ω—É –∫–æ –≤—Å–µ–º –ª–∏—Å—Ç–∞–º
                    for other_ws in data_sheets[1:]:
                        other_ws.column_dimensions[column_letter].width = adjusted_width

            # –î–æ–±–∞–≤–ª—è–µ–º —Ñ–∏–ª—å—Ç—Ä—ã
            ws_data.auto_filter.ref = ws_data.dimensions

            # –ü–æ–¥—Å–≤–µ—Ç–∫–∞ –≤—ã—Å–æ–∫–æ–π —Å—Ö–æ–∂–µ—Å—Ç–∏ (—Ç–æ–ª—å–∫–æ –¥–ª—è –Ω–µ–±–æ–ª—å—à–∏—Ö –ª–∏—Å—Ç–æ–≤)
            if 'Similarity_Score' in df.columns and ws_data.max_row <= 10000:
                similarity_col = df.columns.get_loc('Similarity_Score') + 1

                for row in range(2, ws_data.max_row + 1):  # –ù–∞—á–∏–Ω–∞–µ–º —Å 2-–π —Å—Ç—Ä–æ–∫–∏
                    cell = ws_data.cell(row=row, column=similarity_col)
                    try:
                        if cell.value and float(cell.value) >= 0.9:
                            cell.fill = high_similarity_fill
                    except:
                        pass
        
        # === –õ–ò–°–¢ 2: –°–¢–ê–¢–ò–°–¢–ò–ö–ê ===
        ws_stats = wb.create_sheet("–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞")
        
        # –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        stats_data = [
            ['–ü–∞—Ä–∞–º–µ—Ç—Ä', '–ó–Ω–∞—á–µ–Ω–∏–µ'],
            ['–û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–≤—è–∑–µ–π', len(df)],
            ['–î–∞—Ç–∞ —Å–æ–∑–¥–∞–Ω–∏—è', datetime.now().strftime("%Y-%m-%d %H:%M:%S")],
            ['', '']
        ]
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ç–∏–ø–∞–º –æ—Ç–Ω–æ—à–µ–Ω–∏–π
        if 'Relation_Type' in df.columns:
            stats_data.append(['–¢–∏–ø—ã –æ—Ç–Ω–æ—à–µ–Ω–∏–π', '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ'])
            relation_counts = df['Relation_Type'].value_counts()
            for relation_type, count in relation_counts.items():
                stats_data.append([relation_type, count])
            stats_data.append(['', ''])
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å—Ö–æ–∂–µ—Å—Ç–∏
        if 'Similarity_Score' in df.columns:
            stats_data.extend([
                ['–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å—Ö–æ–∂–µ—Å—Ç–∏', ''],
                ['–°—Ä–µ–¥–Ω—è—è —Å—Ö–æ–∂–µ—Å—Ç—å', f"{df['Similarity_Score'].mean():.3f}"],
                ['–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è —Å—Ö–æ–∂–µ—Å—Ç—å', f"{df['Similarity_Score'].max():.3f}"],
                ['–ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —Å—Ö–æ–∂–µ—Å—Ç—å', f"{df['Similarity_Score'].min():.3f}"],
                ['–ú–µ–¥–∏–∞–Ω–Ω–∞—è —Å—Ö–æ–∂–µ—Å—Ç—å', f"{df['Similarity_Score'].median():.3f}"],
                ['', '']
            ])
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –ø–æ–∏—Å–∫–æ–≤—ã–º –¥–≤–∏–∂–∫–∞–º
        if 'Search_Engine' in df.columns:
            stats_data.append(['–ü–æ–∏—Å–∫–æ–≤—ã–µ –¥–≤–∏–∂–∫–∏', '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ'])
            engine_counts = df['Search_Engine'].value_counts()
            for engine, count in engine_counts.items():
                stats_data.append([engine, count])
        
        # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        for row_data in stats_data:
            ws_stats.append(row_data)
        
        # –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        for col in range(1, 3):
            cell = ws_stats.cell(row=1, column=col)
            cell.font = header_font
            cell.fill = header_fill
            cell.alignment = header_alignment
        
        # –ê–≤—Ç–æ–ø–æ–¥–±–æ—Ä —à–∏—Ä–∏–Ω—ã –¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        for column in ws_stats.columns:
            max_length = 0
            column_letter = column[0].column_letter
            
            for cell in column:
                try:
                    if len(str(cell.value)) > max_length:
                        max_length = len(str(cell.value))
                except:
                    pass
            
            adjusted_width = min(max_length + 2, 40)
            ws_stats.column_dimensions[column_letter].width = adjusted_width
        
        # === –õ–ò–°–¢ 3: –ú–ï–¢–ê–î–ê–ù–ù–´–ï ===
        if metadata:
            ws_meta = wb.create_sheet("–ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ")
            
            meta_data = [['–ü–∞—Ä–∞–º–µ—Ç—Ä', '–ó–Ω–∞—á–µ–Ω–∏–µ']]
            for key, value in metadata.items():
                meta_data.append([key, str(value)])
            
            for row_data in meta_data:
                ws_meta.append(row_data)
            
            # –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
            for col in range(1, 3):
                cell = ws_meta.cell(row=1, column=col)
                cell.font = header_font
                cell.fill = header_fill
                cell.alignment = header_alignment
            
            # –ê–≤—Ç–æ–ø–æ–¥–±–æ—Ä —à–∏—Ä–∏–Ω—ã –¥–ª—è –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
            for column in ws_meta.columns:
                max_length = 0
                column_letter = column[0].column_letter
                
                for cell in column:
                    try:
                        if len(str(cell.value)) > max_length:
                            max_length = len(str(cell.value))
                    except:
                        pass
                
                adjusted_width = min(max_length + 2, 40)
                ws_meta.column_dimensions[column_letter].width = adjusted_width
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∞–π–ª
        wb.save(excel_file)
        logger.info(f"‚úÖ Excel file created successfully: {excel_file}")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        logger.info(f"üìä File statistics:")
        logger.info(f"   Records: {len(df):,}")
        if 'Relation_Type' in df.columns:
            relation_counts = df['Relation_Type'].value_counts()
            for relation_type, count in relation_counts.items():
                logger.info(f"   {relation_type}: {count:,}")
        
        return True
        
    except Exception as e:
        logger.error(f"Error creating Excel file: {e}")
        return False


def main():
    parser = argparse.ArgumentParser(description='Convert CSV to Excel with formatting')
    parser.add_argument('csv_file', help='Input CSV file')
    parser.add_argument('-o', '--output', help='Output Excel file')
    parser.add_argument('--metadata', help='JSON metadata file')
    
    args = parser.parse_args()
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –≤—ã—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª
    if args.output:
        excel_file = args.output
    else:
        csv_path = Path(args.csv_file)
        excel_file = csv_path.with_suffix('.xlsx')
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –µ—Å–ª–∏ –µ—Å—Ç—å
    metadata = None
    if args.metadata and os.path.exists(args.metadata):
        import json
        with open(args.metadata, 'r') as f:
            metadata = json.load(f)
    
    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º
    success = create_excel_with_formatting(args.csv_file, excel_file, metadata)
    
    if success:
        print(f"‚úÖ Conversion completed: {excel_file}")
        return 0
    else:
        print(f"‚ùå Conversion failed")
        return 1


if __name__ == "__main__":
    exit(main())
